{"cells":[{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"St_QJeO0Ot4T"},"source":["## CSKG Setup, Installation and Downloads"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"lh3FS4mJOt4W"},"outputs":[],"source":["import os\n","# Clone repos\n","os.chdir('/home/jaleed/Jaleed/SSG-VQA/SSG')\n","if os.path.isdir('cskg')==False:\n","    !git clone https://github.com/usc-isi-i2/cskg\n","os.chdir('cskg')\n","if os.path.isdir('grounding/graphify')==False:\n","    !git clone https://github.com/ucinlp/mowgli-uci\n","    !mv mowgli-uci/* grounding/\n","# Remove versions from packge names in dependencies to minimize conflict\n","if os.path.isfile('requirements1.txt')==False:\n","    file2 = open(\"requirements1.txt\",\"w\")\n","    with open(\"requirements.txt\", \"r\") as file1:\n","        for pkgver in file1:\n","            if 'kgtk' in pkgver:\n","                continue\n","            if 'demjson' in pkgver:\n","                continue\n","            if '==' in pkgver:\n","                [pkg, ver] = pkgver.split('==')\n","                file2.write(pkg+'\\n')\n","            if ' @ ' in pkgver:\n","                [pkg, ver] = pkgver.split(' @ ')\n","                file2.write(pkg+'\\n')\n","    file1.close()\n","    file2.close()\n","\n","if os.path.isfile('grounding/requirements1.txt')==False:\n","    file2 = open(\"grounding/requirements1.txt\",\"w\")\n","    with open(\"grounding/requirements.txt\", \"r\") as file1:\n","        for pkgver in file1:\n","            if '==' in pkgver:\n","                [pkg, ver] = pkgver.split('==')\n","                file2.write(pkg+'\\n')\n","    file1.close()\n","    file2.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"dKNT7AlbOt4X"},"outputs":[],"source":["!pip install --upgrade pip setuptools==57.5.0\n","!pip install --upgrade python-pushover\n","!python -m pip install kgtk==0.5.0\n","!python -m pip install -r requirements1.txt --no-cache-dir\n","!python -m pip install -r grounding/requirements1.txt --no-cache-dir\n","!conda install --yes faiss-cpu -c pytorch #-n mowgli\n","!python -m spacy download en_core_web_lg\n","!python -m pip install kgtk==0.5.0\n","!python -m pip install altair"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"XMl7AlBbOt4Y"},"outputs":[],"source":["!kgtk --version\n","!kgtk query -h"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3LzuKw9cOt4Y"},"outputs":[],"source":["# Downloads:\n","# 1) download all files from https://drive.google.com/drive/u/1/folders/16347KHSloJJZIbgC9V5gH7_pRx0CzjPQ\n","# and place in 'cskg/output' folder, and unzip all\n","# 2) move BERT embeddings ('bert_nli_large_w2v_format.txt.gz') to 'cskg/output/embeddings'\n","# 3) download numberbatch\n","# !wget https://conceptnet.s3.amazonaws.com/downloads/2019/numberbatch/numberbatch-19.08.txt.gz -P output/embeddings/\n","\n","# Unzip Downloads:\n","#!gunzip -k output/*.txt.gz\n","#!gunzip -k output/*.tsv.gz\n","#!gunzip -k output/embeddings/*.txt.gz\n","\n","# Run these in terminal:\n","# sudo apt-get update -y\n","# sudo apt-get upgrade -y\n","# sudo apt-get install -y graphviz\n","# python -m pip install graphviz\n","# sudo apt-get install -y xdg-utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1rcRwnvlOt4Y","outputId":"5751157e-0af4-4750-c402-68763250a682"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/jaleed/Jaleed/SSG-VQA/SSG/cskg\n"]}],"source":["%cd /home/jaleed/Jaleed/SSG-VQA/SSG/cskg"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"tags":["parameters"],"id":"yKJe6SZSOt4Z"},"outputs":[],"source":["# Parameters\n","cskg_path = \"output\" #\"../output\"\n","kg = \"cskg_connected.kgtk.gz\" #kg = \"cskg.tsv.gz\"\n","nkg = \"cskg-normalized.kgtk.gz\"\n","delete_database = \"yes\""]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"Dr09_lI_Ot4Z"},"outputs":[],"source":["import io\n","import os\n","import subprocess\n","import sys\n","import numpy as np\n","import pandas as pd\n","import altair as alt"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"rbK1qQcHOt4a"},"outputs":[],"source":["os.environ['CSKG'] = cskg_path\n","os.environ['KG'] = \"{}/{}\".format(cskg_path, kg)\n","os.environ['NKG'] = \"{}/{}\".format(cskg_path, nkg)\n","os.environ['STORE'] = \"{}/wikidata.sqlite3.db\".format(cskg_path)\n","os.environ['kypher'] = \"kgtk query --graph-cache \" + os.environ['STORE']"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"9BWQeQjWOt4a"},"outputs":[],"source":["def bar_chart(data, x_column, y_column, title=\"\", width=800):\n","    \"\"\"Construct a simple bar chart with two properties\"\"\"\n","    bars = alt.Chart(data).mark_bar().encode(\n","        y=alt.Y(y_column, sort='-x'),\n","        x=x_column\n","    ).properties(\n","        title=title,\n","        width=width\n","    )\n","\n","    text = bars.mark_text(\n","        align='left',\n","        baseline='middle',\n","        dx=3  # Nudges text to right so it doesn't appear on top of the bar\n","    ).encode(\n","        text=x_column\n","    )\n","\n","    return (bars + text)\n","\n","import io\n","import pandas\n","import subprocess\n","\n","def shell_df(command, shell=False, **kwargs):\n","    \"\"\"\n","    Takes a shell command as a string and and reads the result into a Pandas DataFrame.\n","\n","    Additional keyword arguments are passed through to pandas.read_csv.\n","\n","    :param command: a shell command that returns tabular data\n","    :type command: str\n","    :param shell: passed to subprocess.Popen\n","    :type shell: bool\n","\n","    :return: a pandas dataframe\n","    :rtype: :class:`pandas.dataframe`\n","    \"\"\"\n","    proc = subprocess.Popen(command,\n","                            shell=shell,\n","                            stdout=subprocess.PIPE,\n","                            stderr=subprocess.PIPE)\n","    output, error = proc.communicate()\n","\n","    if proc.returncode == 0:\n","        if error:\n","            print(error.decode())\n","        with io.StringIO(output.decode()) as buffer:\n","            return pandas.read_csv(buffer, **kwargs)\n","    else:\n","        message = (\"Shell command returned non-zero exit status: {0}\\n\\n\"\n","                   \"Command was:\\n{1}\\n\\n\"\n","                   \"Standard error was:\\n{2}\")\n","        raise IOError(message.format(proc.returncode, command, error.decode()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cmbOyHKHOt4a"},"outputs":[],"source":["# CSKG Embeddings\n","graph_emb = \"trans_log_dot_0.1.tsv.gz\" #graph embedding output file - TransE\n","text_emb = \"cskg_embeddings_bert_nli_large.txt.gz\" #text embedding output file - BERT\n","distance='cosine' #embedding distance metric"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BWlpLYHqOt4b"},"outputs":[],"source":["import os\n","from pathlib import Path\n","import gzip\n","import pickle as pkl\n","import faiss\n","import numpy as np\n","from typing import Callable, List, Tuple\n","import json\n","import hashlib\n","import logging\n","from tqdm import tqdm\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BL-XEfS8Ot4b","outputId":"1ce27e9a-4748-42d3-82f0-0ca82519f31b"},"outputs":[{"name":"stdout","output_type":"stream","text":["output\n","output/trans_log_dot_0.1.tsv.gz\n","output/cskg_embeddings_bert_nli_large.txt.gz\n"]}],"source":["os.environ['CSKG'] = cskg_path\n","os.environ['GE'] = \"{}/{}\".format(cskg_path, graph_emb)\n","os.environ['TE'] = \"{}/{}\".format(cskg_path, text_emb)\n","graph_emb_path = os.environ['GE']\n","text_emb_path = os.environ['TE']\n","!echo $CSKG\n","!echo $GE\n","!echo $TE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bA4H1vq5Ot4b"},"outputs":[],"source":["# Utilities\n","\n","class Vocab:\n","    def __init__(self, words) -> None:\n","        self.idx_to_word = words\n","        self.word_to_idx = {word: idx for idx, word in enumerate(words)}\n","\n","def read_embedding_file(embedding_file: Path, dim: int, emb_col=1) -> Tuple[Vocab, np.ndarray]:\n","\n","    logger.debug(f'Reading embeddings from {embedding_file}')\n","\n","    shape = tuple([count_lines(embedding_file), dim])\n","\n","    with gzip.open(embedding_file, 'r') as f:\n","\n","        embeddings = np.zeros(shape, dtype=np.float32)\n","\n","        if emb_col!=1:\n","            header=next(f)\n","        i=0\n","        words = []\n","        for line in tqdm(f, total=shape[0]):\n","            line=line.decode()\n","            if emb_col==1:\n","                node, *embedding = line.split()\n","            else:\n","                line_data=line.split()\n","                if line_data[1]=='embedding_sentence': continue\n","                node=line_data[0]\n","                embedding=line_data[2].split(',')\n","            embedding = np.array([float(x) for x in embedding])\n","            words.append(node)\n","            embeddings[i] = embedding\n","            i+=1\n","\n","    vocab = Vocab(words)\n","\n","    return vocab, embeddings\n","\n","def count_lines(embedding_file: Path):\n","    with gzip.open(embedding_file, 'r') as f:\n","        i=0\n","        for line in f:\n","            i+=1\n","    return i\n","\n","def build_index(metric: str, embeddings: np.ndarray):\n","\n","    logger.debug(f'Building search index')\n","\n","    if metric == 'cosine':\n","        index = faiss.IndexFlatIP(embeddings.shape[-1])\n","    elif metric == 'l2':\n","        index = faiss.IndexFlatL2(embeddings.shape[-1])\n","    else:\n","        raise ValueError(f'Bad metric: {metric}')\n","\n","    index.add(embeddings)\n","\n","    return index\n","\n","logger = logging.getLogger(__name__)\n","logging.basicConfig(level=logging.INFO)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_f2vuaQOt4b","outputId":"ca3193d3-4b3e-4ebc-af7d-0fd294352e3f"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████████████████████████| 2160968/2160968 [01:29<00:00, 24086.51it/s]\n"]}],"source":["# Load graph embeddings\n","graph_dim = 100 # Dimension of the graph embeddings for our example's file\n","graph_vocab, graph_embeddings = read_embedding_file(graph_emb_path,graph_dim)\n","graph_index = build_index(distance, graph_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"L44GmHQSOt4b"},"outputs":[],"source":["# Load text embeddings\n","#text_dim = 1024 # Dimension of the text embeddings for our example's file\n","#text_vocab, text_embeddings = read_embedding_file(text_emb_path, text_dim, emb_col=2)\n","#text_index = build_index(distance, text_embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"QjLHfbzBOt4b"},"outputs":[],"source":["import time\n","for i in range(0,1):\n","    t = time.time()\n","    command = \"$kypher -i $NKG --limit 10 \\\n","                --match '(n1)-[r]->(n2)' \\\n","                --where 'n1 = \\\"\" + '/c/en/person' + \"\\\" AND n2=\\\"\" + '/c/en/racket' + \"\\\"'\"\n","#   --where 'n1 = \\\"\" + '/c/en/woman' + \"\\\" AND r.label=\\\"\" + '/r/RelatedTo' + \"\\\"'\"\n","    stats = shell_df(command, shell=True, sep='\\t')\n","    print(str(time.time()-t)+' seconds.') # 25sec\n","    print(stats)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyIEZDrjOt4b"},"outputs":[],"source":["command = \"$kypher -i $NKG --limit 25 \\\n","                --match '(n1)-[r]->(n2)' \\\n","                --where 'n1 = \\\"\" + '/c/en/door' + \"\\\" AND n2=\\\"\" + '/c/en/house' + \"\\\"'\"\n","stats = shell_df(command, shell=True, sep='\\t')\n","print(stats)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"tags":[],"id":"iM7YdbCwOt4c"},"outputs":[],"source":["command = \"$kypher -i $NKG \\\n","                --match '(n1)-[r]->(n2)' \\\n","                --where 'n1 = \\\"\" + '/c/en/helmet' + \"\\\"'\"\n","stats = shell_df(command, shell=True, sep='\\t')\n","print(stats)"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"977RJZVYOt4c"},"source":["## Scene Graph Generation"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"tags":[],"id":"DNhTH21kOt4c","outputId":"60efa29e-972b-4e0c-d409-2b5b305e5168"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/jaleed/Jaleed/SSG-VQA/SSG/Scene\n","2408978.jpg\n","2022-08-10 17:51:08,713 maskrcnn_benchmark INFO: Using 1 GPUs\n","2022-08-10 17:51:08,713 maskrcnn_benchmark INFO: AMP_VERBOSE: False\n","DATALOADER:\n","  ASPECT_RATIO_GROUPING: True\n","  NUM_WORKERS: 4\n","  SIZE_DIVISIBILITY: 32\n","DATASETS:\n","  TEST: ('GQA_stanford_filtered_with_attribute_test',)\n","  TO_TEST: None\n","  TRAIN: ('GQA_stanford_filtered_with_attribute_train',)\n","  VAL: ('GQA_stanford_filtered_with_attribute_val',)\n","DETECTED_SGG_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out\n","DTYPE: float16\n","GLOVE_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/glove\n","INPUT:\n","  BRIGHTNESS: 0.0\n","  CONTRAST: 0.0\n","  HUE: 0.0\n","  MAX_SIZE_TEST: 1000\n","  MAX_SIZE_TRAIN: 1000\n","  MIN_SIZE_TEST: 600\n","  MIN_SIZE_TRAIN: (600,)\n","  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n","  PIXEL_STD: [1.0, 1.0, 1.0]\n","  SATURATION: 0.0\n","  TO_BGR255: True\n","  VERTICAL_FLIP_PROB_TRAIN: 0.0\n","MODEL:\n","  ATTRIBUTE_ON: False\n","  BACKBONE:\n","    CONV_BODY: R-101-FPN\n","    FREEZE_CONV_BODY_AT: 2\n","  CLS_AGNOSTIC_BBOX_REG: False\n","  DEVICE: cuda\n","  FBNET:\n","    ARCH: default\n","    ARCH_DEF: \n","    BN_TYPE: bn\n","    DET_HEAD_BLOCKS: []\n","    DET_HEAD_LAST_SCALE: 1.0\n","    DET_HEAD_STRIDE: 0\n","    DW_CONV_SKIP_BN: True\n","    DW_CONV_SKIP_RELU: True\n","    KPTS_HEAD_BLOCKS: []\n","    KPTS_HEAD_LAST_SCALE: 0.0\n","    KPTS_HEAD_STRIDE: 0\n","    MASK_HEAD_BLOCKS: []\n","    MASK_HEAD_LAST_SCALE: 0.0\n","    MASK_HEAD_STRIDE: 0\n","    RPN_BN_TYPE: \n","    RPN_HEAD_BLOCKS: 0\n","    SCALE_FACTOR: 1.0\n","    WIDTH_DIVISOR: 1\n","  FLIP_AUG: False\n","  FPN:\n","    USE_GN: False\n","    USE_RELU: False\n","  GROUP_NORM:\n","    DIM_PER_GP: -1\n","    EPSILON: 1e-05\n","    NUM_GROUPS: 32\n","  KEYPOINT_ON: False\n","  MASK_ON: False\n","  META_ARCHITECTURE: GeneralizedRCNN\n","  PRETRAINED_DETECTOR_CKPT: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","  RELATION_ON: True\n","  RESNETS:\n","    BACKBONE_OUT_CHANNELS: 256\n","    DEFORMABLE_GROUPS: 1\n","    NUM_GROUPS: 32\n","    RES2_OUT_CHANNELS: 256\n","    RES5_DILATION: 1\n","    STAGE_WITH_DCN: (False, False, False, False)\n","    STEM_FUNC: StemWithFixedBatchNorm\n","    STEM_OUT_CHANNELS: 64\n","    STRIDE_IN_1X1: False\n","    TRANS_FUNC: BottleneckWithFixedBatchNorm\n","    WIDTH_PER_GROUP: 8\n","    WITH_MODULATED_DCN: False\n","  RETINANET:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n","    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n","    BBOX_REG_BETA: 0.11\n","    BBOX_REG_WEIGHT: 4.0\n","    BG_IOU_THRESHOLD: 0.4\n","    FG_IOU_THRESHOLD: 0.5\n","    INFERENCE_TH: 0.05\n","    LOSS_ALPHA: 0.25\n","    LOSS_GAMMA: 2.0\n","    NMS_TH: 0.4\n","    NUM_CLASSES: 81\n","    NUM_CONVS: 4\n","    OCTAVE: 2.0\n","    PRE_NMS_TOP_N: 1000\n","    PRIOR_PROB: 0.01\n","    SCALES_PER_OCTAVE: 3\n","    STRADDLE_THRESH: 0\n","    USE_C5: True\n","  RETINANET_ON: False\n","  ROI_ATTRIBUTE_HEAD:\n","    ATTRIBUTE_BGFG_RATIO: 3\n","    ATTRIBUTE_BGFG_SAMPLE: True\n","    ATTRIBUTE_LOSS_WEIGHT: 1.0\n","    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n","    MAX_ATTRIBUTES: 10\n","    NUM_ATTRIBUTES: 201\n","    POS_WEIGHT: 50.0\n","    PREDICTOR: FPNPredictor\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","    USE_BINARY_LOSS: True\n","  ROI_BOX_HEAD:\n","    CONV_HEAD_DIM: 256\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n","    MLP_HEAD_DIM: 4096\n","    NUM_CLASSES: 151\n","    NUM_STACKED_CONVS: 4\n","    POOLER_RESOLUTION: 7\n","    POOLER_SAMPLING_RATIO: 2\n","    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n","    PREDICTOR: FPNPredictor\n","    USE_GN: False\n","  ROI_HEADS:\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n","    BG_IOU_THRESHOLD: 0.3\n","    DETECTIONS_PER_IMG: 80\n","    FG_IOU_THRESHOLD: 0.5\n","    NMS: 0.3\n","    NMS_FILTER_DUPLICATES: True\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_PER_CLS_TOPN: 300\n","    SCORE_THRESH: 0.01\n","    USE_FPN: True\n","  ROI_KEYPOINT_HEAD:\n","    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n","    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    NUM_CLASSES: 17\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    PREDICTOR: KeypointRCNNPredictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","  ROI_MASK_HEAD:\n","    CONV_LAYERS: (256, 256, 256, 256)\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    POSTPROCESS_MASKS: False\n","    POSTPROCESS_MASKS_THRESHOLD: 0.5\n","    PREDICTOR: MaskRCNNC4Predictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","    USE_GN: False\n","  ROI_RELATION_HEAD:\n","    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n","    BATCH_SIZE_PER_IMAGE: 1024\n","    CAUSAL:\n","      CONTEXT_LAYER: motifs\n","      EFFECT_ANALYSIS: True\n","      EFFECT_TYPE: none\n","      FUSION_TYPE: sum\n","      SEPARATE_SPATIAL: False\n","      SPATIAL_FOR_VISION: True\n","    CONTEXT_DROPOUT_RATE: 0.2\n","    CONTEXT_HIDDEN_DIM: 512\n","    CONTEXT_OBJ_LAYER: 1\n","    CONTEXT_POOLING_DIM: 4096\n","    CONTEXT_REL_LAYER: 1\n","    EMBED_DIM: 200\n","    FEATURE_EXTRACTOR: RelationFeatureExtractor\n","    LABEL_SMOOTHING_LOSS: False\n","    NUM_CLASSES: 51\n","    NUM_SAMPLE_PER_GT_REL: 4\n","    POOLING_ALL_LEVELS: True\n","    POSITIVE_FRACTION: 0.25\n","    PREDICTOR: CausalAnalysisPredictor\n","    PREDICT_USE_BIAS: True\n","    PREDICT_USE_VISION: True\n","    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n","    REQUIRE_BOX_OVERLAP: False\n","    TRANSFORMER:\n","      DROPOUT_RATE: 0.1\n","      INNER_DIM: 2048\n","      KEY_DIM: 64\n","      NUM_HEAD: 8\n","      OBJ_LAYER: 4\n","      REL_LAYER: 2\n","      VAL_DIM: 64\n","    USE_GT_BOX: False\n","    USE_GT_OBJECT_LABEL: False\n","  RPN:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n","    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BG_IOU_THRESHOLD: 0.3\n","    FG_IOU_THRESHOLD: 0.7\n","    FPN_POST_NMS_PER_BATCH: False\n","    FPN_POST_NMS_TOP_N_TEST: 1000\n","    FPN_POST_NMS_TOP_N_TRAIN: 1000\n","    MIN_SIZE: 0\n","    NMS_THRESH: 0.7\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_TOP_N_TEST: 1000\n","    POST_NMS_TOP_N_TRAIN: 1000\n","    PRE_NMS_TOP_N_TEST: 6000\n","    PRE_NMS_TOP_N_TRAIN: 6000\n","    RPN_HEAD: SingleConvRPNHead\n","    RPN_MID_CHANNEL: 256\n","    STRADDLE_THRESH: 0\n","    USE_FPN: True\n","  RPN_ONLY: False\n","  VGG:\n","    VGG16_OUT_CHANNELS: 512\n","  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n","OUTPUT_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","PATHS_CATALOG: /home/jaleed/Jaleed/SSG-VQA/SSG/Scene/maskrcnn_benchmark/config/paths_catalog.py\n","PATHS_DATA: /home/jaleed/Jaleed/SSG-VQA/SSG/Scene/maskrcnn_benchmark/config/../data/datasets\n","SOLVER:\n","  BASE_LR: 0.01\n","  BIAS_LR_FACTOR: 1\n","  CHECKPOINT_PERIOD: 2000\n","  CLIP_NORM: 5.0\n","  GAMMA: 0.1\n","  GRAD_NORM_CLIP: 5.0\n","  IMS_PER_BATCH: 16\n","  MAX_ITER: 40000\n","  MOMENTUM: 0.9\n","  PRE_VAL: True\n","  PRINT_GRAD_FREQ: 4000\n","  SCHEDULE:\n","    COOLDOWN: 0\n","    FACTOR: 0.1\n","    MAX_DECAY_STEP: 3\n","    PATIENCE: 2\n","    THRESHOLD: 0.001\n","    TYPE: WarmupReduceLROnPlateau\n","  STEPS: (10000, 16000)\n","  TO_VAL: True\n","  UPDATE_SCHEDULE_DURING_LOAD: False\n","  VAL_PERIOD: 2000\n","  WARMUP_FACTOR: 0.1\n","  WARMUP_ITERS: 500\n","  WARMUP_METHOD: linear\n","  WEIGHT_DECAY: 0.0001\n","  WEIGHT_DECAY_BIAS: 0.0\n","TEST:\n","  ALLOW_LOAD_FROM_CACHE: False\n","  BBOX_AUG:\n","    ENABLED: False\n","    H_FLIP: False\n","    MAX_SIZE: 4000\n","    SCALES: ()\n","    SCALE_H_FLIP: False\n","  CUSTUM_EVAL: True\n","  CUSTUM_PATH: /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_inp\n","  DETECTIONS_PER_IMG: 100\n","  EXPECTED_RESULTS: []\n","  EXPECTED_RESULTS_SIGMA_TOL: 4\n","  IMS_PER_BATCH: 1\n","  RELATION:\n","    IOU_THRESHOLD: 0.5\n","    LATER_NMS_PREDICTION_THRES: 0.5\n","    MULTIPLE_PREDS: False\n","    REQUIRE_OVERLAP: False\n","    SYNC_GATHER: True\n","  SAVE_PROPOSALS: False\n","2022-08-10 17:51:08,714 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n","2022-08-10 17:51:15,811 maskrcnn_benchmark INFO: \n","PyTorch version: 1.4.0\n","Is debug build: No\n","CUDA used to build PyTorch: 10.1\n","\n","OS: Ubuntu 18.04.6 LTS\n","GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","CMake version: version 3.10.2\n","\n","Python version: 3.7\n","Is CUDA available: Yes\n","CUDA runtime version: 10.1.105\n","GPU models and configuration: GPU 0: TITAN Xp\n","Nvidia driver version: 440.33.01\n","cuDNN version: Could not collect\n","\n","Versions of relevant libraries:\n","[pip3] numpy==1.21.5\n","[pip3] torch==1.4.0\n","[pip3] torchtext==0.4.0\n","[pip3] torchvision==0.5.0\n","[conda] blas                      1.0                         mkl  \n","[conda] mkl                       2021.4.0           h06a4308_640  \n","[conda] mkl-service               2.4.0            py37h7f8727e_0  \n","[conda] mkl_fft                   1.3.1            py37hd3c417c_0  \n","[conda] mkl_random                1.2.2            py37h51133e4_0  \n","[conda] pytorch                   1.4.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch\n","[conda] torchtext                 0.4.0                    pypi_0    pypi\n","[conda] torchvision               0.5.0                py37_cu101    pytorch\n","        Pillow (9.2.0)\n","2022-08-10 17:51:19,328 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n","2022-08-10 17:51:19,328 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n","2022-08-10 17:51:19,352 maskrcnn_benchmark.data.build INFO: Loading data statistics from: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/GQA_stanford_filtered_with_attribute_train_statistics.cache\n","2022-08-10 17:51:19,353 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n","loading word vectors from /home/jaleed/Jaleed/SSG-VQA/SSG/glove/glove.6B.200d.pt\n","__background__ -> __background__ \n","fail on __background__\n","loading word vectors from /home/jaleed/Jaleed/SSG-VQA/SSG/glove/glove.6B.200d.pt\n","__background__ -> __background__ \n","fail on __background__\n","INIT SAVE DIR /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","get_checkpoint_file /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/last_checkpoint\n","last_saved /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n","2022-08-10 17:51:32,664 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n","100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 12.43it/s]\n","=====> /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out/custom_data_info.json SAVED !\n","2022-08-10 17:51:46,745 maskrcnn_benchmark.inference INFO: Start evaluation on GQA_stanford_filtered_with_attribute_test dataset(1 images).\n","100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.96s/it]\n","2022-08-10 17:51:48,784 maskrcnn_benchmark.inference INFO: Total run time: 0:00:02.038150 (2.0381503105163574 s / img per device, on 1 devices)\n","2022-08-10 17:51:48,784 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:01.612810 (1.6128103733062744 s / img per device, on 1 devices)\n","=====> /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out/custom_prediction.json SAVED !\n","/home/jaleed/Jaleed/SSG-VQA/SSG/Scene\n","2402809.jpg\n","2022-08-10 17:51:55,805 maskrcnn_benchmark INFO: Using 1 GPUs\n","2022-08-10 17:51:55,805 maskrcnn_benchmark INFO: AMP_VERBOSE: False\n","DATALOADER:\n","  ASPECT_RATIO_GROUPING: True\n","  NUM_WORKERS: 4\n","  SIZE_DIVISIBILITY: 32\n","DATASETS:\n","  TEST: ('GQA_stanford_filtered_with_attribute_test',)\n","  TO_TEST: None\n","  TRAIN: ('GQA_stanford_filtered_with_attribute_train',)\n","  VAL: ('GQA_stanford_filtered_with_attribute_val',)\n","DETECTED_SGG_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out\n","DTYPE: float16\n","GLOVE_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/glove\n","INPUT:\n","  BRIGHTNESS: 0.0\n","  CONTRAST: 0.0\n","  HUE: 0.0\n","  MAX_SIZE_TEST: 1000\n","  MAX_SIZE_TRAIN: 1000\n","  MIN_SIZE_TEST: 600\n","  MIN_SIZE_TRAIN: (600,)\n","  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n","  PIXEL_STD: [1.0, 1.0, 1.0]\n","  SATURATION: 0.0\n","  TO_BGR255: True\n","  VERTICAL_FLIP_PROB_TRAIN: 0.0\n","MODEL:\n","  ATTRIBUTE_ON: False\n","  BACKBONE:\n","    CONV_BODY: R-101-FPN\n","    FREEZE_CONV_BODY_AT: 2\n","  CLS_AGNOSTIC_BBOX_REG: False\n","  DEVICE: cuda\n","  FBNET:\n","    ARCH: default\n","    ARCH_DEF: \n","    BN_TYPE: bn\n","    DET_HEAD_BLOCKS: []\n","    DET_HEAD_LAST_SCALE: 1.0\n","    DET_HEAD_STRIDE: 0\n","    DW_CONV_SKIP_BN: True\n","    DW_CONV_SKIP_RELU: True\n","    KPTS_HEAD_BLOCKS: []\n","    KPTS_HEAD_LAST_SCALE: 0.0\n","    KPTS_HEAD_STRIDE: 0\n","    MASK_HEAD_BLOCKS: []\n","    MASK_HEAD_LAST_SCALE: 0.0\n","    MASK_HEAD_STRIDE: 0\n","    RPN_BN_TYPE: \n","    RPN_HEAD_BLOCKS: 0\n","    SCALE_FACTOR: 1.0\n","    WIDTH_DIVISOR: 1\n","  FLIP_AUG: False\n","  FPN:\n","    USE_GN: False\n","    USE_RELU: False\n","  GROUP_NORM:\n","    DIM_PER_GP: -1\n","    EPSILON: 1e-05\n","    NUM_GROUPS: 32\n","  KEYPOINT_ON: False\n","  MASK_ON: False\n","  META_ARCHITECTURE: GeneralizedRCNN\n","  PRETRAINED_DETECTOR_CKPT: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","  RELATION_ON: True\n","  RESNETS:\n","    BACKBONE_OUT_CHANNELS: 256\n","    DEFORMABLE_GROUPS: 1\n","    NUM_GROUPS: 32\n","    RES2_OUT_CHANNELS: 256\n","    RES5_DILATION: 1\n","    STAGE_WITH_DCN: (False, False, False, False)\n","    STEM_FUNC: StemWithFixedBatchNorm\n","    STEM_OUT_CHANNELS: 64\n","    STRIDE_IN_1X1: False\n","    TRANS_FUNC: BottleneckWithFixedBatchNorm\n","    WIDTH_PER_GROUP: 8\n","    WITH_MODULATED_DCN: False\n","  RETINANET:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n","    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n","    BBOX_REG_BETA: 0.11\n","    BBOX_REG_WEIGHT: 4.0\n","    BG_IOU_THRESHOLD: 0.4\n","    FG_IOU_THRESHOLD: 0.5\n","    INFERENCE_TH: 0.05\n","    LOSS_ALPHA: 0.25\n","    LOSS_GAMMA: 2.0\n","    NMS_TH: 0.4\n","    NUM_CLASSES: 81\n","    NUM_CONVS: 4\n","    OCTAVE: 2.0\n","    PRE_NMS_TOP_N: 1000\n","    PRIOR_PROB: 0.01\n","    SCALES_PER_OCTAVE: 3\n","    STRADDLE_THRESH: 0\n","    USE_C5: True\n","  RETINANET_ON: False\n","  ROI_ATTRIBUTE_HEAD:\n","    ATTRIBUTE_BGFG_RATIO: 3\n","    ATTRIBUTE_BGFG_SAMPLE: True\n","    ATTRIBUTE_LOSS_WEIGHT: 1.0\n","    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n","    MAX_ATTRIBUTES: 10\n","    NUM_ATTRIBUTES: 201\n","    POS_WEIGHT: 50.0\n","    PREDICTOR: FPNPredictor\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","    USE_BINARY_LOSS: True\n","  ROI_BOX_HEAD:\n","    CONV_HEAD_DIM: 256\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n","    MLP_HEAD_DIM: 4096\n","    NUM_CLASSES: 151\n","    NUM_STACKED_CONVS: 4\n","    POOLER_RESOLUTION: 7\n","    POOLER_SAMPLING_RATIO: 2\n","    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n","    PREDICTOR: FPNPredictor\n","    USE_GN: False\n","  ROI_HEADS:\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n","    BG_IOU_THRESHOLD: 0.3\n","    DETECTIONS_PER_IMG: 80\n","    FG_IOU_THRESHOLD: 0.5\n","    NMS: 0.3\n","    NMS_FILTER_DUPLICATES: True\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_PER_CLS_TOPN: 300\n","    SCORE_THRESH: 0.01\n","    USE_FPN: True\n","  ROI_KEYPOINT_HEAD:\n","    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n","    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    NUM_CLASSES: 17\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    PREDICTOR: KeypointRCNNPredictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","  ROI_MASK_HEAD:\n","    CONV_LAYERS: (256, 256, 256, 256)\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    POSTPROCESS_MASKS: False\n","    POSTPROCESS_MASKS_THRESHOLD: 0.5\n","    PREDICTOR: MaskRCNNC4Predictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","    USE_GN: False\n","  ROI_RELATION_HEAD:\n","    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n","    BATCH_SIZE_PER_IMAGE: 1024\n","    CAUSAL:\n","      CONTEXT_LAYER: motifs\n","      EFFECT_ANALYSIS: True\n","      EFFECT_TYPE: none\n","      FUSION_TYPE: sum\n","      SEPARATE_SPATIAL: False\n","      SPATIAL_FOR_VISION: True\n","    CONTEXT_DROPOUT_RATE: 0.2\n","    CONTEXT_HIDDEN_DIM: 512\n","    CONTEXT_OBJ_LAYER: 1\n","    CONTEXT_POOLING_DIM: 4096\n","    CONTEXT_REL_LAYER: 1\n","    EMBED_DIM: 200\n","    FEATURE_EXTRACTOR: RelationFeatureExtractor\n","    LABEL_SMOOTHING_LOSS: False\n","    NUM_CLASSES: 51\n","    NUM_SAMPLE_PER_GT_REL: 4\n","    POOLING_ALL_LEVELS: True\n","    POSITIVE_FRACTION: 0.25\n","    PREDICTOR: CausalAnalysisPredictor\n","    PREDICT_USE_BIAS: True\n","    PREDICT_USE_VISION: True\n","    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n","    REQUIRE_BOX_OVERLAP: False\n","    TRANSFORMER:\n","      DROPOUT_RATE: 0.1\n","      INNER_DIM: 2048\n","      KEY_DIM: 64\n","      NUM_HEAD: 8\n","      OBJ_LAYER: 4\n","      REL_LAYER: 2\n","      VAL_DIM: 64\n","    USE_GT_BOX: False\n","    USE_GT_OBJECT_LABEL: False\n","  RPN:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n","    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BG_IOU_THRESHOLD: 0.3\n","    FG_IOU_THRESHOLD: 0.7\n","    FPN_POST_NMS_PER_BATCH: False\n","    FPN_POST_NMS_TOP_N_TEST: 1000\n","    FPN_POST_NMS_TOP_N_TRAIN: 1000\n","    MIN_SIZE: 0\n","    NMS_THRESH: 0.7\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_TOP_N_TEST: 1000\n","    POST_NMS_TOP_N_TRAIN: 1000\n","    PRE_NMS_TOP_N_TEST: 6000\n","    PRE_NMS_TOP_N_TRAIN: 6000\n","    RPN_HEAD: SingleConvRPNHead\n","    RPN_MID_CHANNEL: 256\n","    STRADDLE_THRESH: 0\n","    USE_FPN: True\n","  RPN_ONLY: False\n","  VGG:\n","    VGG16_OUT_CHANNELS: 512\n","  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n","OUTPUT_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","PATHS_CATALOG: /home/jaleed/Jaleed/SSG-VQA/SSG/Scene/maskrcnn_benchmark/config/paths_catalog.py\n","PATHS_DATA: /home/jaleed/Jaleed/SSG-VQA/SSG/Scene/maskrcnn_benchmark/config/../data/datasets\n","SOLVER:\n","  BASE_LR: 0.01\n","  BIAS_LR_FACTOR: 1\n","  CHECKPOINT_PERIOD: 2000\n","  CLIP_NORM: 5.0\n","  GAMMA: 0.1\n","  GRAD_NORM_CLIP: 5.0\n","  IMS_PER_BATCH: 16\n","  MAX_ITER: 40000\n","  MOMENTUM: 0.9\n","  PRE_VAL: True\n","  PRINT_GRAD_FREQ: 4000\n","  SCHEDULE:\n","    COOLDOWN: 0\n","    FACTOR: 0.1\n","    MAX_DECAY_STEP: 3\n","    PATIENCE: 2\n","    THRESHOLD: 0.001\n","    TYPE: WarmupReduceLROnPlateau\n","  STEPS: (10000, 16000)\n","  TO_VAL: True\n","  UPDATE_SCHEDULE_DURING_LOAD: False\n","  VAL_PERIOD: 2000\n","  WARMUP_FACTOR: 0.1\n","  WARMUP_ITERS: 500\n","  WARMUP_METHOD: linear\n","  WEIGHT_DECAY: 0.0001\n","  WEIGHT_DECAY_BIAS: 0.0\n","TEST:\n","  ALLOW_LOAD_FROM_CACHE: False\n","  BBOX_AUG:\n","    ENABLED: False\n","    H_FLIP: False\n","    MAX_SIZE: 4000\n","    SCALES: ()\n","    SCALE_H_FLIP: False\n","  CUSTUM_EVAL: True\n","  CUSTUM_PATH: /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_inp\n","  DETECTIONS_PER_IMG: 100\n","  EXPECTED_RESULTS: []\n","  EXPECTED_RESULTS_SIGMA_TOL: 4\n","  IMS_PER_BATCH: 1\n","  RELATION:\n","    IOU_THRESHOLD: 0.5\n","    LATER_NMS_PREDICTION_THRES: 0.5\n","    MULTIPLE_PREDS: False\n","    REQUIRE_OVERLAP: False\n","    SYNC_GATHER: True\n","  SAVE_PROPOSALS: False\n","2022-08-10 17:51:55,806 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n","2022-08-10 17:52:01,693 maskrcnn_benchmark INFO: \n","PyTorch version: 1.4.0\n","Is debug build: No\n","CUDA used to build PyTorch: 10.1\n","\n","OS: Ubuntu 18.04.6 LTS\n","GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","CMake version: version 3.10.2\n","\n","Python version: 3.7\n","Is CUDA available: Yes\n","CUDA runtime version: 10.1.105\n","GPU models and configuration: GPU 0: TITAN Xp\n","Nvidia driver version: 440.33.01\n","cuDNN version: Could not collect\n","\n","Versions of relevant libraries:\n","[pip3] numpy==1.21.5\n","[pip3] torch==1.4.0\n","[pip3] torchtext==0.4.0\n","[pip3] torchvision==0.5.0\n","[conda] blas                      1.0                         mkl  \n","[conda] mkl                       2021.4.0           h06a4308_640  \n","[conda] mkl-service               2.4.0            py37h7f8727e_0  \n","[conda] mkl_fft                   1.3.1            py37hd3c417c_0  \n","[conda] mkl_random                1.2.2            py37h51133e4_0  \n","[conda] pytorch                   1.4.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch\n","[conda] torchtext                 0.4.0                    pypi_0    pypi\n","[conda] torchvision               0.5.0                py37_cu101    pytorch\n","        Pillow (9.2.0)\n","2022-08-10 17:52:04,868 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n","2022-08-10 17:52:04,868 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n","2022-08-10 17:52:04,868 maskrcnn_benchmark.data.build INFO: Loading data statistics from: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/GQA_stanford_filtered_with_attribute_train_statistics.cache\n","2022-08-10 17:52:04,868 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n","loading word vectors from /home/jaleed/Jaleed/SSG-VQA/SSG/glove/glove.6B.200d.pt\n","__background__ -> __background__ \n","fail on __background__\n","loading word vectors from /home/jaleed/Jaleed/SSG-VQA/SSG/glove/glove.6B.200d.pt\n","__background__ -> __background__ \n","fail on __background__\n","INIT SAVE DIR /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","get_checkpoint_file /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/last_checkpoint\n","last_saved /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n","2022-08-10 17:52:08,002 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n","100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 127.83it/s]\n","=====> /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out/custom_data_info.json SAVED !\n","2022-08-10 17:52:09,530 maskrcnn_benchmark.inference INFO: Start evaluation on GQA_stanford_filtered_with_attribute_test dataset(1 images).\n","100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it]\n","2022-08-10 17:52:10,668 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.137766 (1.1377663612365723 s / img per device, on 1 devices)\n","2022-08-10 17:52:10,668 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:00.860996 (0.8609955310821533 s / img per device, on 1 devices)\n","=====> /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out/custom_prediction.json SAVED !\n","/home/jaleed/Jaleed/SSG-VQA/SSG/Scene\n","2285.jpg\n","2022-08-10 17:52:14,450 maskrcnn_benchmark INFO: Using 1 GPUs\n","2022-08-10 17:52:14,450 maskrcnn_benchmark INFO: AMP_VERBOSE: False\n","DATALOADER:\n","  ASPECT_RATIO_GROUPING: True\n","  NUM_WORKERS: 4\n","  SIZE_DIVISIBILITY: 32\n","DATASETS:\n","  TEST: ('GQA_stanford_filtered_with_attribute_test',)\n","  TO_TEST: None\n","  TRAIN: ('GQA_stanford_filtered_with_attribute_train',)\n","  VAL: ('GQA_stanford_filtered_with_attribute_val',)\n","DETECTED_SGG_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out\n","DTYPE: float16\n","GLOVE_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/glove\n","INPUT:\n","  BRIGHTNESS: 0.0\n","  CONTRAST: 0.0\n","  HUE: 0.0\n","  MAX_SIZE_TEST: 1000\n","  MAX_SIZE_TRAIN: 1000\n","  MIN_SIZE_TEST: 600\n","  MIN_SIZE_TRAIN: (600,)\n","  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n","  PIXEL_STD: [1.0, 1.0, 1.0]\n","  SATURATION: 0.0\n","  TO_BGR255: True\n","  VERTICAL_FLIP_PROB_TRAIN: 0.0\n","MODEL:\n","  ATTRIBUTE_ON: False\n","  BACKBONE:\n","    CONV_BODY: R-101-FPN\n","    FREEZE_CONV_BODY_AT: 2\n","  CLS_AGNOSTIC_BBOX_REG: False\n","  DEVICE: cuda\n","  FBNET:\n","    ARCH: default\n","    ARCH_DEF: \n","    BN_TYPE: bn\n","    DET_HEAD_BLOCKS: []\n","    DET_HEAD_LAST_SCALE: 1.0\n","    DET_HEAD_STRIDE: 0\n","    DW_CONV_SKIP_BN: True\n","    DW_CONV_SKIP_RELU: True\n","    KPTS_HEAD_BLOCKS: []\n","    KPTS_HEAD_LAST_SCALE: 0.0\n","    KPTS_HEAD_STRIDE: 0\n","    MASK_HEAD_BLOCKS: []\n","    MASK_HEAD_LAST_SCALE: 0.0\n","    MASK_HEAD_STRIDE: 0\n","    RPN_BN_TYPE: \n","    RPN_HEAD_BLOCKS: 0\n","    SCALE_FACTOR: 1.0\n","    WIDTH_DIVISOR: 1\n","  FLIP_AUG: False\n","  FPN:\n","    USE_GN: False\n","    USE_RELU: False\n","  GROUP_NORM:\n","    DIM_PER_GP: -1\n","    EPSILON: 1e-05\n","    NUM_GROUPS: 32\n","  KEYPOINT_ON: False\n","  MASK_ON: False\n","  META_ARCHITECTURE: GeneralizedRCNN\n","  PRETRAINED_DETECTOR_CKPT: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","  RELATION_ON: True\n","  RESNETS:\n","    BACKBONE_OUT_CHANNELS: 256\n","    DEFORMABLE_GROUPS: 1\n","    NUM_GROUPS: 32\n","    RES2_OUT_CHANNELS: 256\n","    RES5_DILATION: 1\n","    STAGE_WITH_DCN: (False, False, False, False)\n","    STEM_FUNC: StemWithFixedBatchNorm\n","    STEM_OUT_CHANNELS: 64\n","    STRIDE_IN_1X1: False\n","    TRANS_FUNC: BottleneckWithFixedBatchNorm\n","    WIDTH_PER_GROUP: 8\n","    WITH_MODULATED_DCN: False\n","  RETINANET:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n","    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n","    BBOX_REG_BETA: 0.11\n","    BBOX_REG_WEIGHT: 4.0\n","    BG_IOU_THRESHOLD: 0.4\n","    FG_IOU_THRESHOLD: 0.5\n","    INFERENCE_TH: 0.05\n","    LOSS_ALPHA: 0.25\n","    LOSS_GAMMA: 2.0\n","    NMS_TH: 0.4\n","    NUM_CLASSES: 81\n","    NUM_CONVS: 4\n","    OCTAVE: 2.0\n","    PRE_NMS_TOP_N: 1000\n","    PRIOR_PROB: 0.01\n","    SCALES_PER_OCTAVE: 3\n","    STRADDLE_THRESH: 0\n","    USE_C5: True\n","  RETINANET_ON: False\n","  ROI_ATTRIBUTE_HEAD:\n","    ATTRIBUTE_BGFG_RATIO: 3\n","    ATTRIBUTE_BGFG_SAMPLE: True\n","    ATTRIBUTE_LOSS_WEIGHT: 1.0\n","    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n","    MAX_ATTRIBUTES: 10\n","    NUM_ATTRIBUTES: 201\n","    POS_WEIGHT: 50.0\n","    PREDICTOR: FPNPredictor\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","    USE_BINARY_LOSS: True\n","  ROI_BOX_HEAD:\n","    CONV_HEAD_DIM: 256\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n","    MLP_HEAD_DIM: 4096\n","    NUM_CLASSES: 151\n","    NUM_STACKED_CONVS: 4\n","    POOLER_RESOLUTION: 7\n","    POOLER_SAMPLING_RATIO: 2\n","    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n","    PREDICTOR: FPNPredictor\n","    USE_GN: False\n","  ROI_HEADS:\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n","    BG_IOU_THRESHOLD: 0.3\n","    DETECTIONS_PER_IMG: 80\n","    FG_IOU_THRESHOLD: 0.5\n","    NMS: 0.3\n","    NMS_FILTER_DUPLICATES: True\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_PER_CLS_TOPN: 300\n","    SCORE_THRESH: 0.01\n","    USE_FPN: True\n","  ROI_KEYPOINT_HEAD:\n","    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n","    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    NUM_CLASSES: 17\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    PREDICTOR: KeypointRCNNPredictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","  ROI_MASK_HEAD:\n","    CONV_LAYERS: (256, 256, 256, 256)\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    POSTPROCESS_MASKS: False\n","    POSTPROCESS_MASKS_THRESHOLD: 0.5\n","    PREDICTOR: MaskRCNNC4Predictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","    USE_GN: False\n","  ROI_RELATION_HEAD:\n","    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n","    BATCH_SIZE_PER_IMAGE: 1024\n","    CAUSAL:\n","      CONTEXT_LAYER: motifs\n","      EFFECT_ANALYSIS: True\n","      EFFECT_TYPE: none\n","      FUSION_TYPE: sum\n","      SEPARATE_SPATIAL: False\n","      SPATIAL_FOR_VISION: True\n","    CONTEXT_DROPOUT_RATE: 0.2\n","    CONTEXT_HIDDEN_DIM: 512\n","    CONTEXT_OBJ_LAYER: 1\n","    CONTEXT_POOLING_DIM: 4096\n","    CONTEXT_REL_LAYER: 1\n","    EMBED_DIM: 200\n","    FEATURE_EXTRACTOR: RelationFeatureExtractor\n","    LABEL_SMOOTHING_LOSS: False\n","    NUM_CLASSES: 51\n","    NUM_SAMPLE_PER_GT_REL: 4\n","    POOLING_ALL_LEVELS: True\n","    POSITIVE_FRACTION: 0.25\n","    PREDICTOR: CausalAnalysisPredictor\n","    PREDICT_USE_BIAS: True\n","    PREDICT_USE_VISION: True\n","    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n","    REQUIRE_BOX_OVERLAP: False\n","    TRANSFORMER:\n","      DROPOUT_RATE: 0.1\n","      INNER_DIM: 2048\n","      KEY_DIM: 64\n","      NUM_HEAD: 8\n","      OBJ_LAYER: 4\n","      REL_LAYER: 2\n","      VAL_DIM: 64\n","    USE_GT_BOX: False\n","    USE_GT_OBJECT_LABEL: False\n","  RPN:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n","    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BG_IOU_THRESHOLD: 0.3\n","    FG_IOU_THRESHOLD: 0.7\n","    FPN_POST_NMS_PER_BATCH: False\n","    FPN_POST_NMS_TOP_N_TEST: 1000\n","    FPN_POST_NMS_TOP_N_TRAIN: 1000\n","    MIN_SIZE: 0\n","    NMS_THRESH: 0.7\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_TOP_N_TEST: 1000\n","    POST_NMS_TOP_N_TRAIN: 1000\n","    PRE_NMS_TOP_N_TEST: 6000\n","    PRE_NMS_TOP_N_TRAIN: 6000\n","    RPN_HEAD: SingleConvRPNHead\n","    RPN_MID_CHANNEL: 256\n","    STRADDLE_THRESH: 0\n","    USE_FPN: True\n","  RPN_ONLY: False\n","  VGG:\n","    VGG16_OUT_CHANNELS: 512\n","  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n","OUTPUT_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","PATHS_CATALOG: /home/jaleed/Jaleed/SSG-VQA/SSG/Scene/maskrcnn_benchmark/config/paths_catalog.py\n","PATHS_DATA: /home/jaleed/Jaleed/SSG-VQA/SSG/Scene/maskrcnn_benchmark/config/../data/datasets\n","SOLVER:\n","  BASE_LR: 0.01\n","  BIAS_LR_FACTOR: 1\n","  CHECKPOINT_PERIOD: 2000\n","  CLIP_NORM: 5.0\n","  GAMMA: 0.1\n","  GRAD_NORM_CLIP: 5.0\n","  IMS_PER_BATCH: 16\n","  MAX_ITER: 40000\n","  MOMENTUM: 0.9\n","  PRE_VAL: True\n","  PRINT_GRAD_FREQ: 4000\n","  SCHEDULE:\n","    COOLDOWN: 0\n","    FACTOR: 0.1\n","    MAX_DECAY_STEP: 3\n","    PATIENCE: 2\n","    THRESHOLD: 0.001\n","    TYPE: WarmupReduceLROnPlateau\n","  STEPS: (10000, 16000)\n","  TO_VAL: True\n","  UPDATE_SCHEDULE_DURING_LOAD: False\n","  VAL_PERIOD: 2000\n","  WARMUP_FACTOR: 0.1\n","  WARMUP_ITERS: 500\n","  WARMUP_METHOD: linear\n","  WEIGHT_DECAY: 0.0001\n","  WEIGHT_DECAY_BIAS: 0.0\n","TEST:\n","  ALLOW_LOAD_FROM_CACHE: False\n","  BBOX_AUG:\n","    ENABLED: False\n","    H_FLIP: False\n","    MAX_SIZE: 4000\n","    SCALES: ()\n","    SCALE_H_FLIP: False\n","  CUSTUM_EVAL: True\n","  CUSTUM_PATH: /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_inp\n","  DETECTIONS_PER_IMG: 100\n","  EXPECTED_RESULTS: []\n","  EXPECTED_RESULTS_SIGMA_TOL: 4\n","  IMS_PER_BATCH: 1\n","  RELATION:\n","    IOU_THRESHOLD: 0.5\n","    LATER_NMS_PREDICTION_THRES: 0.5\n","    MULTIPLE_PREDS: False\n","    REQUIRE_OVERLAP: False\n","    SYNC_GATHER: True\n","  SAVE_PROPOSALS: False\n","2022-08-10 17:52:14,451 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n","2022-08-10 17:52:17,765 maskrcnn_benchmark INFO: \n","PyTorch version: 1.4.0\n","Is debug build: No\n","CUDA used to build PyTorch: 10.1\n","\n","OS: Ubuntu 18.04.6 LTS\n","GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","CMake version: version 3.10.2\n","\n","Python version: 3.7\n","Is CUDA available: Yes\n","CUDA runtime version: 10.1.105\n","GPU models and configuration: GPU 0: TITAN Xp\n","Nvidia driver version: 440.33.01\n","cuDNN version: Could not collect\n","\n","Versions of relevant libraries:\n","[pip3] numpy==1.21.5\n","[pip3] torch==1.4.0\n","[pip3] torchtext==0.4.0\n","[pip3] torchvision==0.5.0\n","[conda] blas                      1.0                         mkl  \n","[conda] mkl                       2021.4.0           h06a4308_640  \n","[conda] mkl-service               2.4.0            py37h7f8727e_0  \n","[conda] mkl_fft                   1.3.1            py37hd3c417c_0  \n","[conda] mkl_random                1.2.2            py37h51133e4_0  \n","[conda] pytorch                   1.4.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch\n","[conda] torchtext                 0.4.0                    pypi_0    pypi\n","[conda] torchvision               0.5.0                py37_cu101    pytorch\n","        Pillow (9.2.0)\n","2022-08-10 17:52:20,974 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n","2022-08-10 17:52:20,975 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n","2022-08-10 17:52:20,975 maskrcnn_benchmark.data.build INFO: Loading data statistics from: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/GQA_stanford_filtered_with_attribute_train_statistics.cache\n","2022-08-10 17:52:20,975 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n","loading word vectors from /home/jaleed/Jaleed/SSG-VQA/SSG/glove/glove.6B.200d.pt\n","__background__ -> __background__ \n","fail on __background__\n","loading word vectors from /home/jaleed/Jaleed/SSG-VQA/SSG/glove/glove.6B.200d.pt\n","__background__ -> __background__ \n","fail on __background__\n","INIT SAVE DIR /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","get_checkpoint_file /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/last_checkpoint\n","last_saved /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n","2022-08-10 17:52:24,092 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n","100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 82.64it/s]\n","=====> /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out/custom_data_info.json SAVED !\n","2022-08-10 17:52:25,563 maskrcnn_benchmark.inference INFO: Start evaluation on GQA_stanford_filtered_with_attribute_test dataset(1 images).\n","100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.08s/it]\n","2022-08-10 17:52:26,669 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.106525 (1.1065247058868408 s / img per device, on 1 devices)\n","2022-08-10 17:52:26,669 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:00.809717 (0.8097167015075684 s / img per device, on 1 devices)\n","=====> /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out/custom_prediction.json SAVED !\n","/home/jaleed/Jaleed/SSG-VQA/SSG/Scene\n","1206.jpg\n","2022-08-10 17:52:30,422 maskrcnn_benchmark INFO: Using 1 GPUs\n","2022-08-10 17:52:30,422 maskrcnn_benchmark INFO: AMP_VERBOSE: False\n","DATALOADER:\n","  ASPECT_RATIO_GROUPING: True\n","  NUM_WORKERS: 4\n","  SIZE_DIVISIBILITY: 32\n","DATASETS:\n","  TEST: ('GQA_stanford_filtered_with_attribute_test',)\n","  TO_TEST: None\n","  TRAIN: ('GQA_stanford_filtered_with_attribute_train',)\n","  VAL: ('GQA_stanford_filtered_with_attribute_val',)\n","DETECTED_SGG_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out\n","DTYPE: float16\n","GLOVE_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/glove\n","INPUT:\n","  BRIGHTNESS: 0.0\n","  CONTRAST: 0.0\n","  HUE: 0.0\n","  MAX_SIZE_TEST: 1000\n","  MAX_SIZE_TRAIN: 1000\n","  MIN_SIZE_TEST: 600\n","  MIN_SIZE_TRAIN: (600,)\n","  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n","  PIXEL_STD: [1.0, 1.0, 1.0]\n","  SATURATION: 0.0\n","  TO_BGR255: True\n","  VERTICAL_FLIP_PROB_TRAIN: 0.0\n","MODEL:\n","  ATTRIBUTE_ON: False\n","  BACKBONE:\n","    CONV_BODY: R-101-FPN\n","    FREEZE_CONV_BODY_AT: 2\n","  CLS_AGNOSTIC_BBOX_REG: False\n","  DEVICE: cuda\n","  FBNET:\n","    ARCH: default\n","    ARCH_DEF: \n","    BN_TYPE: bn\n","    DET_HEAD_BLOCKS: []\n","    DET_HEAD_LAST_SCALE: 1.0\n","    DET_HEAD_STRIDE: 0\n","    DW_CONV_SKIP_BN: True\n","    DW_CONV_SKIP_RELU: True\n","    KPTS_HEAD_BLOCKS: []\n","    KPTS_HEAD_LAST_SCALE: 0.0\n","    KPTS_HEAD_STRIDE: 0\n","    MASK_HEAD_BLOCKS: []\n","    MASK_HEAD_LAST_SCALE: 0.0\n","    MASK_HEAD_STRIDE: 0\n","    RPN_BN_TYPE: \n","    RPN_HEAD_BLOCKS: 0\n","    SCALE_FACTOR: 1.0\n","    WIDTH_DIVISOR: 1\n","  FLIP_AUG: False\n","  FPN:\n","    USE_GN: False\n","    USE_RELU: False\n","  GROUP_NORM:\n","    DIM_PER_GP: -1\n","    EPSILON: 1e-05\n","    NUM_GROUPS: 32\n","  KEYPOINT_ON: False\n","  MASK_ON: False\n","  META_ARCHITECTURE: GeneralizedRCNN\n","  PRETRAINED_DETECTOR_CKPT: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","  RELATION_ON: True\n","  RESNETS:\n","    BACKBONE_OUT_CHANNELS: 256\n","    DEFORMABLE_GROUPS: 1\n","    NUM_GROUPS: 32\n","    RES2_OUT_CHANNELS: 256\n","    RES5_DILATION: 1\n","    STAGE_WITH_DCN: (False, False, False, False)\n","    STEM_FUNC: StemWithFixedBatchNorm\n","    STEM_OUT_CHANNELS: 64\n","    STRIDE_IN_1X1: False\n","    TRANS_FUNC: BottleneckWithFixedBatchNorm\n","    WIDTH_PER_GROUP: 8\n","    WITH_MODULATED_DCN: False\n","  RETINANET:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n","    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n","    BBOX_REG_BETA: 0.11\n","    BBOX_REG_WEIGHT: 4.0\n","    BG_IOU_THRESHOLD: 0.4\n","    FG_IOU_THRESHOLD: 0.5\n","    INFERENCE_TH: 0.05\n","    LOSS_ALPHA: 0.25\n","    LOSS_GAMMA: 2.0\n","    NMS_TH: 0.4\n","    NUM_CLASSES: 81\n","    NUM_CONVS: 4\n","    OCTAVE: 2.0\n","    PRE_NMS_TOP_N: 1000\n","    PRIOR_PROB: 0.01\n","    SCALES_PER_OCTAVE: 3\n","    STRADDLE_THRESH: 0\n","    USE_C5: True\n","  RETINANET_ON: False\n","  ROI_ATTRIBUTE_HEAD:\n","    ATTRIBUTE_BGFG_RATIO: 3\n","    ATTRIBUTE_BGFG_SAMPLE: True\n","    ATTRIBUTE_LOSS_WEIGHT: 1.0\n","    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n","    MAX_ATTRIBUTES: 10\n","    NUM_ATTRIBUTES: 201\n","    POS_WEIGHT: 50.0\n","    PREDICTOR: FPNPredictor\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","    USE_BINARY_LOSS: True\n","  ROI_BOX_HEAD:\n","    CONV_HEAD_DIM: 256\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor\n","    MLP_HEAD_DIM: 4096\n","    NUM_CLASSES: 151\n","    NUM_STACKED_CONVS: 4\n","    POOLER_RESOLUTION: 7\n","    POOLER_SAMPLING_RATIO: 2\n","    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)\n","    PREDICTOR: FPNPredictor\n","    USE_GN: False\n","  ROI_HEADS:\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n","    BG_IOU_THRESHOLD: 0.3\n","    DETECTIONS_PER_IMG: 80\n","    FG_IOU_THRESHOLD: 0.5\n","    NMS: 0.3\n","    NMS_FILTER_DUPLICATES: True\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_PER_CLS_TOPN: 300\n","    SCORE_THRESH: 0.01\n","    USE_FPN: True\n","  ROI_KEYPOINT_HEAD:\n","    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n","    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    NUM_CLASSES: 17\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    PREDICTOR: KeypointRCNNPredictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","  ROI_MASK_HEAD:\n","    CONV_LAYERS: (256, 256, 256, 256)\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    POSTPROCESS_MASKS: False\n","    POSTPROCESS_MASKS_THRESHOLD: 0.5\n","    PREDICTOR: MaskRCNNC4Predictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","    USE_GN: False\n","  ROI_RELATION_HEAD:\n","    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True\n","    BATCH_SIZE_PER_IMAGE: 1024\n","    CAUSAL:\n","      CONTEXT_LAYER: motifs\n","      EFFECT_ANALYSIS: True\n","      EFFECT_TYPE: none\n","      FUSION_TYPE: sum\n","      SEPARATE_SPATIAL: False\n","      SPATIAL_FOR_VISION: True\n","    CONTEXT_DROPOUT_RATE: 0.2\n","    CONTEXT_HIDDEN_DIM: 512\n","    CONTEXT_OBJ_LAYER: 1\n","    CONTEXT_POOLING_DIM: 4096\n","    CONTEXT_REL_LAYER: 1\n","    EMBED_DIM: 200\n","    FEATURE_EXTRACTOR: RelationFeatureExtractor\n","    LABEL_SMOOTHING_LOSS: False\n","    NUM_CLASSES: 51\n","    NUM_SAMPLE_PER_GT_REL: 4\n","    POOLING_ALL_LEVELS: True\n","    POSITIVE_FRACTION: 0.25\n","    PREDICTOR: CausalAnalysisPredictor\n","    PREDICT_USE_BIAS: True\n","    PREDICT_USE_VISION: True\n","    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]\n","    REQUIRE_BOX_OVERLAP: False\n","    TRANSFORMER:\n","      DROPOUT_RATE: 0.1\n","      INNER_DIM: 2048\n","      KEY_DIM: 64\n","      NUM_HEAD: 8\n","      OBJ_LAYER: 4\n","      REL_LAYER: 2\n","      VAL_DIM: 64\n","    USE_GT_BOX: False\n","    USE_GT_OBJECT_LABEL: False\n","  RPN:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDE: (4, 8, 16, 32, 64)\n","    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BG_IOU_THRESHOLD: 0.3\n","    FG_IOU_THRESHOLD: 0.7\n","    FPN_POST_NMS_PER_BATCH: False\n","    FPN_POST_NMS_TOP_N_TEST: 1000\n","    FPN_POST_NMS_TOP_N_TRAIN: 1000\n","    MIN_SIZE: 0\n","    NMS_THRESH: 0.7\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_TOP_N_TEST: 1000\n","    POST_NMS_TOP_N_TRAIN: 1000\n","    PRE_NMS_TOP_N_TEST: 6000\n","    PRE_NMS_TOP_N_TRAIN: 6000\n","    RPN_HEAD: SingleConvRPNHead\n","    RPN_MID_CHANNEL: 256\n","    STRADDLE_THRESH: 0\n","    USE_FPN: True\n","  RPN_ONLY: False\n","  VGG:\n","    VGG16_OUT_CHANNELS: 512\n","  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d\n","OUTPUT_DIR: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","PATHS_CATALOG: /home/jaleed/Jaleed/SSG-VQA/SSG/Scene/maskrcnn_benchmark/config/paths_catalog.py\n","PATHS_DATA: /home/jaleed/Jaleed/SSG-VQA/SSG/Scene/maskrcnn_benchmark/config/../data/datasets\n","SOLVER:\n","  BASE_LR: 0.01\n","  BIAS_LR_FACTOR: 1\n","  CHECKPOINT_PERIOD: 2000\n","  CLIP_NORM: 5.0\n","  GAMMA: 0.1\n","  GRAD_NORM_CLIP: 5.0\n","  IMS_PER_BATCH: 16\n","  MAX_ITER: 40000\n","  MOMENTUM: 0.9\n","  PRE_VAL: True\n","  PRINT_GRAD_FREQ: 4000\n","  SCHEDULE:\n","    COOLDOWN: 0\n","    FACTOR: 0.1\n","    MAX_DECAY_STEP: 3\n","    PATIENCE: 2\n","    THRESHOLD: 0.001\n","    TYPE: WarmupReduceLROnPlateau\n","  STEPS: (10000, 16000)\n","  TO_VAL: True\n","  UPDATE_SCHEDULE_DURING_LOAD: False\n","  VAL_PERIOD: 2000\n","  WARMUP_FACTOR: 0.1\n","  WARMUP_ITERS: 500\n","  WARMUP_METHOD: linear\n","  WEIGHT_DECAY: 0.0001\n","  WEIGHT_DECAY_BIAS: 0.0\n","TEST:\n","  ALLOW_LOAD_FROM_CACHE: False\n","  BBOX_AUG:\n","    ENABLED: False\n","    H_FLIP: False\n","    MAX_SIZE: 4000\n","    SCALES: ()\n","    SCALE_H_FLIP: False\n","  CUSTUM_EVAL: True\n","  CUSTUM_PATH: /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_inp\n","  DETECTIONS_PER_IMG: 100\n","  EXPECTED_RESULTS: []\n","  EXPECTED_RESULTS_SIGMA_TOL: 4\n","  IMS_PER_BATCH: 1\n","  RELATION:\n","    IOU_THRESHOLD: 0.5\n","    LATER_NMS_PREDICTION_THRES: 0.5\n","    MULTIPLE_PREDS: False\n","    REQUIRE_OVERLAP: False\n","    SYNC_GATHER: True\n","  SAVE_PROPOSALS: False\n","2022-08-10 17:52:30,423 maskrcnn_benchmark INFO: Collecting env info (might take some time)\n","2022-08-10 17:52:33,798 maskrcnn_benchmark INFO: \n","PyTorch version: 1.4.0\n","Is debug build: No\n","CUDA used to build PyTorch: 10.1\n","\n","OS: Ubuntu 18.04.6 LTS\n","GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","CMake version: version 3.10.2\n","\n","Python version: 3.7\n","Is CUDA available: Yes\n","CUDA runtime version: 10.1.105\n","GPU models and configuration: GPU 0: TITAN Xp\n","Nvidia driver version: 440.33.01\n","cuDNN version: Could not collect\n","\n","Versions of relevant libraries:\n","[pip3] numpy==1.21.5\n","[pip3] torch==1.4.0\n","[pip3] torchtext==0.4.0\n","[pip3] torchvision==0.5.0\n","[conda] blas                      1.0                         mkl  \n","[conda] mkl                       2021.4.0           h06a4308_640  \n","[conda] mkl-service               2.4.0            py37h7f8727e_0  \n","[conda] mkl_fft                   1.3.1            py37hd3c417c_0  \n","[conda] mkl_random                1.2.2            py37h51133e4_0  \n","[conda] pytorch                   1.4.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch\n","[conda] torchtext                 0.4.0                    pypi_0    pypi\n","[conda] torchvision               0.5.0                py37_cu101    pytorch\n","        Pillow (9.2.0)\n","2022-08-10 17:52:36,992 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n","2022-08-10 17:52:36,992 maskrcnn_benchmark.data.build INFO: get dataset statistics...\n","2022-08-10 17:52:36,992 maskrcnn_benchmark.data.build INFO: Loading data statistics from: /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/GQA_stanford_filtered_with_attribute_train_statistics.cache\n","2022-08-10 17:52:36,992 maskrcnn_benchmark.data.build INFO: ----------------------------------------------------------------------------------------------------\n","loading word vectors from /home/jaleed/Jaleed/SSG-VQA/SSG/glove/glove.6B.200d.pt\n","__background__ -> __background__ \n","fail on __background__\n","loading word vectors from /home/jaleed/Jaleed/SSG-VQA/SSG/glove/glove.6B.200d.pt\n","__background__ -> __background__ \n","fail on __background__\n","INIT SAVE DIR /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet\n","get_checkpoint_file /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/last_checkpoint\n","last_saved /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n","2022-08-10 17:52:40,028 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet/model_0028000.pth\n","100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 136.85it/s]\n","=====> /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out/custom_data_info.json SAVED !\n","2022-08-10 17:52:41,458 maskrcnn_benchmark.inference INFO: Start evaluation on GQA_stanford_filtered_with_attribute_test dataset(1 images).\n","100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.07s/it]\n","2022-08-10 17:52:42,562 maskrcnn_benchmark.inference INFO: Total run time: 0:00:01.103885 (1.1038854122161865 s / img per device, on 1 devices)\n","2022-08-10 17:52:42,562 maskrcnn_benchmark.inference INFO: Model inference time: 0:00:00.813602 (0.8136024475097656 s / img per device, on 1 devices)\n","=====> /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out/custom_prediction.json SAVED !\n","/home/jaleed/Jaleed/SSG-VQA/SSG/Scene\n"]}],"source":["import os\n","import copy\n","import sys\n","import torch\n","import h5py\n","import json\n","import shutil\n","from matplotlib.pyplot import imshow\n","from PIL import Image, ImageDraw\n","import numpy as np\n","from collections import defaultdict\n","from tqdm import tqdm\n","import random\n","from maskrcnn_benchmark.structures.bounding_box import BoxList\n","from maskrcnn_benchmark.structures.boxlist_ops import boxlist_iou\n","eval_inp_img = '/home/jaleed/Jaleed/SSG-VQA/Eval_IO/gqa/0_images'\n","eval_outp_sg = '/home/jaleed/Jaleed/SSG-VQA/Eval_IO/gqa/1_pred_scene_graphs'\n","%cd /home/jaleed/Jaleed/SSG-VQA/SSG/Scene\n","\n","for img_file in os.listdir(eval_inp_img):\n","    if os.path.isdir(eval_outp_sg+'/'+img_file)==False:\n","        print(img_file)\n","        # clear SGG input folder\n","        !rm -r /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_inp\n","        os.mkdir('/home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_inp')\n","        # copy image to SGG input directory from eval_inp_img directory\n","        shutil.copyfile(eval_inp_img+'/'+img_file, '/home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_inp/'+img_file)\n","        # run SGG\n","        !(CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --master_port 10027 --nproc_per_node=1 tools/relation_test_net.py \\\n","            --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n","            MODEL.ROI_RELATION_HEAD.USE_GT_BOX False \\\n","            MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False \\\n","            MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n","            MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE none \\\n","            MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum \\\n","            MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n","            TEST.IMS_PER_BATCH 1 DTYPE \"float16\" \\\n","            GLOVE_DIR /home/jaleed/Jaleed/SSG-VQA/SSG/glove \\\n","            MODEL.PRETRAINED_DETECTOR_CKPT /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet \\\n","            OUTPUT_DIR /home/jaleed/Jaleed/SSG-VQA/SSG/checkpoint/upload_causal_motif_sgdet \\\n","            TEST.CUSTUM_EVAL True \\\n","            TEST.CUSTUM_PATH /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_inp \\\n","            DETECTED_SGG_DIR /home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out)\n","        # copy result from SGG output directory to eval_outp_sg directory\n","        shutil.copytree('/home/jaleed/Jaleed/SSG-VQA/SSG/temp_dir_out', eval_outp_sg+'/'+img_file)\n","\n","        # reset (to avoid mem/IO error) and repeat imports and variables after reset\n","        %reset -f\n","        import os\n","        import copy\n","        import sys\n","        import torch\n","        import h5py\n","        import json\n","        import shutil\n","        from matplotlib.pyplot import imshow\n","        from PIL import Image, ImageDraw\n","        import numpy as np\n","        from collections import defaultdict\n","        from tqdm import tqdm\n","        import random\n","        from maskrcnn_benchmark.structures.bounding_box import BoxList\n","        from maskrcnn_benchmark.structures.boxlist_ops import boxlist_iou\n","        eval_inp_img = '/home/jaleed/Jaleed/SSG-VQA/Eval_IO/gqa/0_images' #repeat for gqa, flickr and coco\n","        eval_outp_sg = '/home/jaleed/Jaleed/SSG-VQA/Eval_IO/gqa/1_pred_scene_graphs'\n","        %cd /home/jaleed/Jaleed/SSG-VQA/SSG/Scene"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hgf7sLXlOt4c"},"outputs":[],"source":["#dir_eval_io = '/home/jaleed/Jaleed/SSG-VQA/Eval_IO/vg/'\n","dir_eval_io = '/home/jaleed/Jaleed/SSG-VQA/Eval_IO/gqa/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N5WjhIsaOt4c"},"outputs":[],"source":["def draw_single_box(pic, box, color='red', draw_info=None):\n","    draw = ImageDraw.Draw(pic)\n","    x1,y1,x2,y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n","    draw.rectangle(((x1, y1), (x2, y2)), outline=color)\n","    if draw_info:\n","        draw.rectangle(((x1, y1), (x1+50, y1+10)), fill=color)\n","        info = draw_info\n","        draw.text((x1, y1), info)\n","\n","def print_list(name, input_list, scores=None):\n","    for i, item in enumerate(input_list):\n","        if scores == None:\n","            print(name + ' ' + str(i) + ': ' + str(item))\n","        else:\n","            print(name + ' ' + str(i) + ': ' + str(item) + '; score: ' + str(scores[i]))\n","\n","def draw_image(img_path, boxes, box_labels, rel_labels, box_scores=None, rel_scores=None):\n","    size = get_size(Image.open(img_path).size)\n","    pic = Image.open(img_path).resize(size)\n","    num_obj = len(boxes)\n","    for i in range(num_obj):\n","        info = str(i) + '_' + box_labels[i]\n","        draw_single_box(pic, boxes[i], draw_info=info)\n","    display(pic)\n","    print('*' * 50)\n","    print_list('box_labels', box_labels, box_scores)\n","    print('*' * 50)\n","    print_list('rel_labels', rel_labels, rel_scores)\n","\n","    return None\n","\n","def get_size(image_size):\n","    min_size = 600\n","    max_size = 1000\n","    w, h = image_size\n","    size = min_size\n","    if max_size is not None:\n","        min_original_size = float(min((w, h)))\n","        max_original_size = float(max((w, h)))\n","        if max_original_size / min_original_size * size > max_size:\n","            size = int(round(max_size * min_original_size / max_original_size))\n","    if (w <= h and w == size) or (h <= w and h == size):\n","        return (w, h)\n","    if w < h:\n","        ow = size\n","        oh = int(size * h / w)\n","    else:\n","        oh = size\n","        ow = int(size * w / h)\n","    return (ow, oh)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4AmIJ0iGOt4c"},"outputs":[],"source":["from PIL import Image\n","import json\n","def load_sg(img_path, box_topk):\n","\n","    img = Image.open(img_path)\n","    custom_prediction_file = open(f'{dir_eval_io}1_pred_scene_graphs/'+img_path.split('0_images/')[1]+'/custom_prediction.json')\n","    custom_prediction = json.load(custom_prediction_file)\n","    custom_data_info_file = open(f'{dir_eval_io}1_pred_scene_graphs/'+img_path.split('0_images/')[1]+'/custom_data_info.json')\n","    custom_data_info = json.load(custom_data_info_file)\n","\n","    image_idx = 0\n","    #box_topk = 5 # select top k bounding boxes, now taken as func arg\n","    rel_topk = int(np.math.factorial(box_topk)/np.math.factorial(box_topk-2)) # select top k relationships\n","    ind_to_classes = custom_data_info['ind_to_classes']\n","    ind_to_predicates = custom_data_info['ind_to_predicates']\n","    boxes = custom_prediction[str(image_idx)]['bbox'][:box_topk]\n","    box_labels = custom_prediction[str(image_idx)]['bbox_labels'][:box_topk]\n","    box_scores = custom_prediction[str(image_idx)]['bbox_scores'][:box_topk]\n","    all_rel_labels = custom_prediction[str(image_idx)]['rel_labels']\n","    all_rel_scores = custom_prediction[str(image_idx)]['rel_scores']\n","    all_rel_pairs = custom_prediction[str(image_idx)]['rel_pairs']\n","\n","    for i in range(len(box_labels)):\n","        box_labels[i] = ind_to_classes[box_labels[i]]\n","\n","    rel_labels = []\n","    rel_scores = []\n","    for i in range(len(all_rel_pairs)):\n","        if all_rel_pairs[i][0] < box_topk and all_rel_pairs[i][1] < box_topk:\n","            rel_scores.append(all_rel_scores[i])\n","            label = str(all_rel_pairs[i][0]) + '_' + box_labels[all_rel_pairs[i][0]] + ' => ' + ind_to_predicates[all_rel_labels[i]] + ' => ' + str(all_rel_pairs[i][1]) + '_' + box_labels[all_rel_pairs[i][1]]\n","            rel_labels.append(label)\n","\n","    rel_labels = rel_labels[:rel_topk]\n","    rel_scores = rel_scores[:rel_topk]\n","\n","    #draw_image(img, boxes, box_labels, rel_labels, box_scores=box_scores, rel_scores=rel_scores)\n","\n","    return box_labels,rel_labels,boxes"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"4KTsnPDLOt4c"},"outputs":[],"source":["import graphviz\n","def draw_graph(nodes,edges):\n","\n","    #init graph\n","    g = graphviz.Digraph('G',format='png')\n","    g.splines='true'\n","    g.overlap='false'\n","\n","    if len(edges)>0:\n","        # prepare nodes/edges\n","        if type(edges[0])==str:\n","            # if input params are (box_labels,rel_labels) from SGG\n","            edges1=list()\n","            for i in range(0,len(edges)):\n","                edge = {}\n","                r1,r2,r3 = edges[i].split(' => ')\n","                [r11,r12] = r1.split('_')\n","                edge['node1_id'] = r11\n","                edge['node1'] = r12\n","                edge['node1_sg'] = True\n","                edge['rel'] = r2\n","                edge['rel_sg'] = True\n","                [r31,r32] = r3.split('_')\n","                edge['node2_id'] = r31\n","                edge['node2'] = r32\n","                edge['node2_sg'] = True\n","                edges1.append(edge)\n","        else:\n","            # if input params are (nodes,edges) from CSKG\n","            edges1 = edges\n","\n","        # build the graph\n","        for i in range(0,len(edges1)):\n","            e = edges1[i]\n","            if e['node1_sg'] == True:\n","                g.node(e['node1_id'],label=e['node1'],shape='rect',style='filled',fillcolor='black',fontcolor='white')\n","            else:\n","                g.node(e['node1_id'],label=e['node1'],shape='ellipse')\n","            if e['node2_sg'] == True:\n","                g.node(e['node2_id'],label=e['node2'],shape='rect',style='filled',fillcolor='black',fontcolor='white')\n","            else:\n","                g.node(e['node2_id'],label=e['node2'],shape='ellipse')\n","            if e['rel_sg'] == True:\n","                g.edge(e['node1_id'],e['node2_id'],label=e['rel'])\n","            else:\n","                g.edge(e['node1_id'],e['node2_id'],label=e['rel'],dir='none') # (CSKG undirected edge)\n","    return g"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"2CIVTTtBOt4c"},"source":["## Parsing SG Concepts to CSKG representation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6yh1VL6Ot4d"},"outputs":[],"source":["def node_similarity(node1,node2):\n","\n","    try:\n","        node1_emb=graph_embeddings[graph_vocab.word_to_idx[node1]]\n","    except:\n","        try:\n","            [node1,x] = node1.split('_')\n","            node1_emb=graph_embeddings[graph_vocab.word_to_idx[node1]]\n","        except:\n","            return 0.0\n","\n","    try:\n","        node2_emb=graph_embeddings[graph_vocab.word_to_idx[node2]]\n","    except:\n","        try:\n","            [node2,x] = node2.split('_')\n","            node2_emb=graph_embeddings[graph_vocab.word_to_idx[node2]]\n","        except:\n","            return 0.0\n","\n","    return cosine_similarity([node1_emb],[node2_emb])[0][0]\n","\n","# def word_similarity(node1,node2):\n","\n","#     try:\n","#         node1_emb=text_embeddings[text_vocab.word_to_idx[node1]]\n","#     except:\n","#         [node1,x] = node1.split('_')\n","#         node1_emb=text_embeddings[text_vocab.word_to_idx[node1]]\n","\n","#     try:\n","#         node2_emb=text_embeddings[text_vocab.word_to_idx[node2]]\n","#     except:\n","#         [node2,x] = node2.split('_')\n","#         node2_emb=text_embeddings[text_vocab.word_to_idx[node2]]\n","\n","#     return cosine_similarity([node1_emb],[node2_emb])[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"5e-r7F3xOt4d"},"outputs":[],"source":["def parse_to_cskg(box_labels,rel_labels):\n","    nodes = list()\n","    edges = list()\n","    for i in range(0,len(box_labels)):\n","        node={}\n","        node['id'] = str(i)\n","        node['label'] = '/c/en/' + box_labels[i].replace(' ','_')\n","        node['sg'] = True\n","        nodes.append(node)\n","    for i in range(0,len(rel_labels)):\n","        edge = {}\n","        rel_node = {}\n","        r1,r2,r3 = rel_labels[i].split(' => ')\n","        [r11,r12] = r1.split('_')\n","        node1_id = r11\n","        node1 = '/c/en/'+r12.replace(' ','_')\n","        rel = '/r/'+r2.replace(' ','_')\n","        [r31,r32] = r3.split('_')\n","        node2_id = r31\n","        node2 = '/c/en/'+r32.replace(' ','_')\n","        edge['node1']=node1\n","        edge['node1_id']=node1_id\n","        edge['node1_sg']=True\n","        edge['rel']=rel\n","        edge['rel_sg']=True\n","        edge['node2']=node2\n","        edge['node2_id']=node2_id\n","        edge['node2_sg']=True\n","        edges.append(edge)\n","    return nodes,edges"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"Ka6ywKHVOt4d"},"source":["## Graph Enrichment"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"PNP7pd8GOt4d"},"outputs":[],"source":["def bb_intersection_over_union(boxA, boxB):\n","    # determine the (x, y)-coordinates of the intersection rectangle\n","    xA = max(boxA[0], boxB[0])\n","    yA = max(boxA[1], boxB[1])\n","    xB = min(boxA[2], boxB[2])\n","    yB = min(boxA[3], boxB[3])\n","    # compute the area of intersection rectangle\n","    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n","    # compute the area of both the prediction and ground-truth\n","    # rectangles\n","    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n","    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n","    # compute the intersection over union by taking the intersection\n","    # area and dividing it by the sum of prediction + ground-truth\n","    # areas - the interesection area\n","    iou = interArea / float(boxAArea + boxBArea - interArea)\n","    # return the intersection over union value\n","    return iou"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6FDc3oehOt4d"},"outputs":[],"source":["def refine_graph(nodes,edges,boxes,box_labels):\n","    # first identify nodes to remove based on graph embedding and location\n","    # in case of similarity, the 2nd node is noted for removal from nodes and edges\n","    # noted edges/nodes are removed\n","    # finally, edges involving no corresponding sg_rel_id are also removed\n","    idx = list()\n","    for i in range(0,len(box_labels)-1):\n","        obj_node1 = '/c/en/' + box_labels[i].replace(' ','_')\n","        obj_node1_box = boxes[i]\n","        for j in range(i+1,len(box_labels)):\n","            obj_node2 = '/c/en/' + box_labels[j].replace(' ','_')\n","            obj_node2_box = boxes[j]\n","            if node_similarity(obj_node1,obj_node2)>0.5 or bb_intersection_over_union(obj_node1_box,obj_node2_box)>0.5:\n","                idx.append(j)\n","    idx = list(set(idx)) # sort the list and remove duplicates\n","    for i in range(0,len(idx)):\n","        node_id = str(idx[i])\n","        # remove this node\n","        j=0\n","        while j < len(nodes):\n","            if nodes[j]['id']==node_id:\n","                nodes.pop(j)\n","            else:\n","                j=j+1\n","        # remove triplets involving this node\n","        j=0\n","        while j < len(edges):\n","            if edges[j]['node1_id']==node_id or edges[j]['node2_id']==node_id:\n","                edges.pop(j)\n","            else:\n","                j=j+1\n","    # remove nodes not in any triplet\n","    i=0\n","    while i < len(nodes):\n","        flag=0\n","        for edge in edges:\n","            if nodes[i]['id'] in [edge['node1_id'],edge['node2_id']]:\n","                flag=1\n","                break\n","        if flag==0:\n","            nodes.pop(i)\n","        else:\n","            i=i+1\n","    return [nodes,edges]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HEGC17RMOt4d"},"outputs":[],"source":["import json\n","gqa_rels_json = json.load(open('../relationships.json'))\n","gqa_dict = json.load(open('../GQA-SGG-dicts-with-attri.json'))\n","gqa_unique_objs = list(dict.fromkeys(gqa_dict['object_count'].keys())) # 150 unique rels in GQA\n","gqa_unique_rels = list(dict.fromkeys(gqa_dict['predicate_count'].keys())) # 50 unique rels in GQA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_aW3mSk_Ot4d"},"outputs":[],"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import csv\n","\n","rels_dict = gqa_dict['predicate_count']\n","rels_dict = {k: v for k, v in sorted(rels_dict.items(), reverse=True, key=lambda item: item[1])}\n","rels_dict = {k: 100*(v/sum(rels_dict.values())) for k, v in rels_dict.items()}\n","# fig = plt.figure(figsize=[100,70])\n","# plt.rcParams[\"font.size\"] = 100\n","# plt.xticks(fontsize = 50, rotation = 60)\n","# plt.xlabel('Predicate')\n","# plt.ylabel('Frequency (%)')\n","# plt.bar(range(len(rels_dict)), rels_dict.values(), tick_label=list(rels_dict.keys()))\n","# plt.savefig(\"/home/jaleed/Jaleed/SSG-VQA/freqplot_rels.png\")\n","\n","#objs_dict = gqa_dict['object_count']\n","# objs_dict = {k: v for k, v in sorted(objs_dict.items(), reverse=True, key=lambda item: item[1])}\n","# objs_dict = {k: 100*(v/sum(objs_dict.values())) for k, v in objs_dict.items()}\n","# fig2 = plt.figure(figsize=[140,60])\n","# plt.rcParams[\"font.size\"] = 100\n","# plt.xticks(fontsize = 50, rotation = 90)\n","# plt.xlabel('Object')\n","# plt.ylabel('Frequency (%)')\n","# plt.bar(range(len(objs_dict)), objs_dict.values(), tick_label=list(objs_dict.keys()))\n","# plt.savefig(\"/home/jaleed/Jaleed/SSG-VQA/freqplot_objs.png\")\n","\n","l = list()\n","l.append(rels_dict)\n","with open('gqa_rels_freq.csv', 'w') as csvfile:\n","    writer = csv.DictWriter(csvfile, fieldnames = rels_dict.keys())\n","    writer.writeheader()\n","    writer.writerows(l)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"csHfh2z9Ot4d"},"outputs":[],"source":["import pandas as pd\n","pd.options.mode.chained_assignment=None\n","import time\n","def extract_from_cskg(nodes):\n","    new_nodes_rels = list()\n","    for node in nodes:\n","        t = time.time()\n","\n","        # Part 1/2: (node, --, --)\n","        command = \"$kypher -i $NKG \\\n","                    --match '(n1)-[]->()' \\\n","                    --where '(n1 = \\\"\" + node['label'] + \"\\\")'\"\n","        stats=shell_df(command, shell=True, sep='\\t')\n","        stats.drop(stats[stats['label']=='label'].index, inplace=True)\n","        # skip the ones that have same node on both sides (e.g. man-similarTo-man)\n","        stats.drop(stats[stats['node1']==stats['node2']].index, inplace=True)\n","        # calculate similarity of nodes in each row\n","        stats['similarity']=np.zeros((len(stats),1))\n","        for i in stats.index:\n","            stats['similarity'][i] = node_similarity(stats['node1'][i],stats['node2'][i])\n","        # remove duplicate rows\n","        stats.drop_duplicates()\n","        # sort stats in descending order by similarity score\n","        stats.sort_values(by=['similarity'], inplace=True, ascending=False)\n","        rels = list(pd.unique(stats['label']))\n","        for rel in rels:\n","            # one instance of each unique rel\n","            sub_stats = stats[stats['label']==rel].head(1)\n","            for i in sub_stats.index:\n","                if sub_stats.loc[i]['similarity']>=0.5:\n","                    new_nodes_rels.append([sub_stats.loc[i]['node1'],sub_stats.loc[i]['label'],\n","                                            sub_stats.loc[i]['node2'],sub_stats.loc[i]['similarity']])\n","\n","        # Part 2/2: (--, --, node)\n","        command = \"$kypher -i $NKG \\\n","                    --match '()-[]->(n2)' \\\n","                    --where '(n2 = \\\"\" + node['label'] + \"\\\")'\"\n","        stats=shell_df(command, shell=True, sep='\\t')\n","        stats.drop(stats[stats['label']=='label'].index, inplace=True)\n","        # skip the ones that have same node on both sides (e.g. man-similarTo-man)\n","        stats.drop(stats[stats['node1']==stats['node2']].index, inplace=True)\n","        # calculate similarity of nodes in each row\n","        stats['similarity']=np.zeros((len(stats),1))\n","        for i in stats.index:\n","            stats['similarity'][i] = node_similarity(stats['node1'][i],stats['node2'][i])\n","        # remove duplicate rows\n","        stats.drop_duplicates()\n","        # sort stats in descending order by similarity score\n","        stats.sort_values(by=['similarity'], inplace=True, ascending=False)\n","        rels = list(pd.unique(stats['label']))\n","        for rel in rels:\n","            # one instance of each unique rel;\n","            sub_stats = stats[stats['label']==rel].head(1)\n","            for i in sub_stats.index:\n","                if sub_stats.loc[i]['similarity']>=0.5:\n","                    new_nodes_rels.append([sub_stats.loc[i]['node1'],sub_stats.loc[i]['label'],\n","                                            sub_stats.loc[i]['node2'],sub_stats.loc[i]['similarity']])\n","\n","        print('Extraction from CSKG done for '+node['label']+' in '+ str(int(time.time()-t)) +' sec)')\n","    return new_nodes_rels"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"j69XYF5_Ot4e"},"outputs":[],"source":["def enrich_graph(nodes,edges):\n","\n","    # extract and add relevant nodes and edges from CSKG\n","    new_nodes_rels = extract_from_cskg(nodes)\n","\n","    new_nodes=list()\n","    new_edges=list()\n","    for new_node_rel in new_nodes_rels:\n","        new_node1 = new_node_rel[0]\n","        new_rel = new_node_rel[1]\n","        new_node2 = new_node_rel[2]\n","\n","        # check if the 1st new node is already present\n","        if (new_node1 in [n['label'] for n in nodes+new_nodes]):\n","            # if yes, link the new edge to the existing node\n","            for n in nodes+new_nodes:\n","                if n['label']==new_node1:\n","                    new_node1_id = n['id']\n","                    new_node1_sg = n['sg']\n","        else:\n","            # otherwise create new node and then link\n","            new_node1_id = str(int(nodes[-1]['id'])+len(new_nodes)+1)\n","            new_node1_sg = False\n","            new_nodes.append({'id':new_node1_id,\n","                              'label':new_node1,\n","                              'sg':new_node1_sg})\n","\n","        # similarly for 2nd new node\n","        if (new_node2 in [n['label'] for n in nodes+new_nodes]):\n","            for n in nodes+new_nodes:\n","                if n['label']==new_node2:\n","                    new_node2_id = n['id']\n","                    new_node2_sg = n['sg']\n","        else:\n","            new_node2_id = str(int(nodes[-1]['id'])+len(new_nodes)+1)\n","            new_node2_sg = False\n","            new_nodes.append({'id':new_node2_id,\n","                              'label':new_node2,\n","                              'sg':new_node2_sg})\n","\n","        new_edge = {'node1': new_node1,\n","                    'node1_id': new_node1_id,\n","                    'node1_sg': new_node1_sg,\n","                    'rel': new_rel,\n","                    'rel_sg': False,\n","                    'node2': new_node2,\n","                    'node2_id': new_node2_id,\n","                    'node2_sg':new_node2_sg}\n","        new_edges.append(new_edge)\n","\n","    nodes1 = nodes + new_nodes\n","    edges1 = edges + new_edges\n","    return nodes1,edges1"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"kFjCR9_vOt4e"},"source":["## Parsing back to SG format for downstream task or evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ta8L4KJGOt4e"},"outputs":[],"source":["def node_to_sg(node):\n","    if '/c/en/' in node['label']:\n","        x = node['label'].split('/')\n","        node_label = x[3]\n","        obj_sim_scores = np.zeros((len(gqa_unique_objs),1))\n","        if node['sg'] == True:\n","            node['label'] = node_label.replace('_',' ')\n","        else:\n","            for i in range(0,len(gqa_unique_objs)):\n","                obj_sim_scores[i]=node_similarity('/c/en/'+node_label,'/c/en/'+gqa_unique_objs[i].replace(' ','_'))\n","            if max(obj_sim_scores)>0.5:\n","                max_index = [n==max(obj_sim_scores) for n in obj_sim_scores].index(True)\n","                node['label'] = gqa_unique_objs[max_index]\n","            else:\n","                node = None\n","    else:\n","        node = None\n","    return node"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4NGTG_gOt4e"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_excel('../CSKGtoSG-rels.xlsx')\n","def parse_to_sg(nodes, edges, gqa_unique_objs=gqa_unique_objs, gqa_unique_rels=gqa_unique_rels):\n","    nodes1=list()\n","    edges1=list()\n","    for node in nodes:\n","        node = node_to_sg(node)\n","        if (node is not None) and (node['label'] not in [n['label'] for n in nodes1]):\n","            nodes1.append(node)\n","    for edge in edges:\n","        node1 = node_to_sg({'id': edge['node1_id'], 'label': edge['node1'], 'sg': edge['node1_sg']})\n","        node2 = node_to_sg({'id': edge['node2_id'], 'label': edge['node2'], 'sg': edge['node2_sg']})\n","        rel = None\n","        # if both nodes exist\n","        if (node1 is not None) and (node2 is not None):\n","            # if node1 or node2 already present, link to it\n","            if node1['label'] in [node['label'] for node in nodes1]:\n","                for node in nodes1:\n","                    if node['label']==node1['label']:\n","                        node1['id'] = node['id']\n","                        node1['sg'] = node['sg']\n","            if node2['label'] in [node['label'] for node in nodes1]:\n","                for node in nodes1:\n","                    if node['label']==node2['label']:\n","                        node2['id'] = node['id']\n","                        node2['sg'] = node['sg']\n","            # process rel if different nodes on both sides\n","            if node1['id']!=node2['id']:\n","                x = edge['rel'].split('/')\n","                x = x[2].replace('_',' ')\n","                if x in gqa_unique_rels:\n","                    rel = x\n","                else:\n","                    for i in df.index:\n","                        if df['cskg_rel'][i].lower() == edge['rel'].lower():\n","                            rel = df['sg_rel'].iloc[i]\n","                if (rel is not None) and str(rel)!='nan':\n","                    edges1.append({\n","                        'node1': node1['label'],\n","                        'node1_id': node1['id'],\n","                        'node1_sg': node1['sg'],\n","                        'rel': rel,\n","                        'rel_sg': edge['rel_sg'],\n","                        'node2': node2['label'],\n","                        'node2_id': node2['id'],\n","                        'node2_sg': node2['sg']\n","                    })\n","    # discard nodes that are not used in edges1\n","    nodes1 = [n for n in nodes1 if n['id'] in list(set([e['node1_id'] for e in edges1]+[e['node2_id'] for e in edges1]))]\n","    return nodes1, edges1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"COiq5ZAXOt4e"},"outputs":[],"source":["def save_sg_format(img_path, nodes, edges):\n","    custom_prediction_file = open(f'{dir_eval_io}1_pred_scene_graphs/'+img_path.split('0_images/')[1]+'/custom_prediction.json')\n","    custom_prediction = json.load(custom_prediction_file)\n","    custom_data_info_file = open(f'{dir_eval_io}1_pred_scene_graphs/'+img_path.split('0_images/')[1]+'/custom_data_info.json')\n","    custom_data_info = json.load(custom_data_info_file)\n","    ind_to_classes = custom_data_info['ind_to_classes']\n","    ind_to_predicates = custom_data_info['ind_to_predicates']\n","    for node in nodes:\n","        if node['sg']==False:\n","            bbox = custom_prediction['0']['bbox']\n","            bbox.append(bbox[1])\n","            custom_prediction['0']['bbox'] = bbox\n","            bbox_labels = custom_prediction['0']['bbox_labels']\n","            bbox_labels.append(ind_to_classes.index(node['label']))\n","            custom_prediction['0']['bbox_labels'] = bbox_labels\n","            bbox_scores = custom_prediction['0']['bbox_scores']\n","            bbox_scores.append(max(bbox_scores))\n","            custom_prediction['0']['bbox_scores'] = bbox_scores\n","    for edge in edges:\n","        if edge['rel_sg']==False:\n","            bbox_labels = custom_prediction['0']['bbox_labels']\n","            node1 = bbox_labels.index(ind_to_classes.index(edge['node1']))\n","            node2 = bbox_labels.index(ind_to_classes.index(edge['node2']))\n","            rel_pairs = custom_prediction['0']['rel_pairs']\n","            rel_pairs.insert(0,[node1,node2])\n","            custom_prediction['0']['rel_pairs'] = rel_pairs\n","            rel_labels = custom_prediction['0']['rel_labels']\n","            rel_labels.insert(0,ind_to_predicates.index(edge['rel']))\n","            custom_prediction['0']['rel_labels'] = rel_labels\n","            rel_scores = custom_prediction['0']['rel_scores']\n","            rel_scores.insert(0,max(rel_scores))\n","            custom_prediction['0']['rel_scores'] = rel_scores\n","            rel_all_scores = custom_prediction['0']['rel_all_scores']\n","            rel_all_scores.insert(0,rel_all_scores[1])\n","            custom_prediction['0']['rel_all_scores'] = rel_all_scores\n","    os.mkdir(f'{dir_eval_io}2_enriched_scene_graphs/'+img_path.split('0_images/')[1])\n","    with open(f'{dir_eval_io}2_enriched_scene_graphs/'+img_path.split('0_images/')[1]+'/custom_prediction.json', 'w') as f:\n","        json.dump(custom_prediction, f)\n","    with open(f'{dir_eval_io}2_enriched_scene_graphs/'+img_path.split('0_images/')[1]+'/custom_data_info.json', 'w') as f:\n","        json.dump(custom_data_info, f)"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"SavBEBIvOt4j"},"source":["## Putting it all together"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aog2B2RFOt4j"},"outputs":[],"source":["from PIL import Image\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"tags":[],"id":"5QyqCI3nOt4j"},"outputs":[],"source":["for filename in os.listdir(f'{dir_eval_io}0_images/'):\n","    img_path = f'{dir_eval_io}0_images/{filename}'\n","\n","    if os.path.exists(f'{dir_eval_io}graph_figures/'+img_path.split('0_images/')[1]):\n","        print('***** EXISTS: '+ img_path +' *****')\n","        continue\n","    else:\n","\n","        print('***** PROCESSING '+ img_path +' *****')\n","\n","        # Load scene graph\n","        [box_labels,rel_labels,boxes] = load_sg(img_path, 10) # 2nd arg is max objects\n","\n","        # Draw scene graph\n","        g = draw_graph(box_labels,rel_labels)\n","        g.render(f'{dir_eval_io}graph_figures/'+img_path.split('0_images/')[1]+'/01_sg')\n","\n","        # Parse to CSKG\n","        [nodes1,edges1] = parse_to_cskg(box_labels,rel_labels)\n","        g1 = draw_graph(nodes1,edges1)\n","        g1.render(f'{dir_eval_io}graph_figures/'+img_path.split('0_images/')[1]+'/02_sg_parsed')\n","\n","        # Refine graph\n","        [nodes2,edges2]=refine_graph(nodes1,edges1,boxes,box_labels)\n","        g2 = draw_graph(nodes2,edges2)\n","        g2.render(f'{dir_eval_io}graph_figures/'+img_path.split('0_images/')[1]+'/03_sg_parsed_refined')\n","\n","        # Enrich graph\n","        [nodes3,edges3] = enrich_graph(nodes2,edges2)\n","        g3 = draw_graph(nodes3,edges3)\n","        g3.render(f'{dir_eval_io}graph_figures/'+img_path.split('0_images/')[1]+'/04_sg_parsed_refined_enriched')\n","\n","        # Parse to SG\n","        [nodes4,edges4] = parse_to_sg(nodes3,edges3)\n","        g4 = draw_graph(nodes4,edges4)\n","        g4.render(f'{dir_eval_io}graph_figures/'+img_path.split('0_images/')[1]+'/05_sg_parsed_refined_enriched_reverseparsed')\n","\n","        # Save final graph as JSON\n","        graph = {'nodes':nodes4, 'edges':edges4}\n","        with open(f'{dir_eval_io}graph_figures/'+img_path.split('0_images/')[1]+'.json', 'w') as f:\n","            json.dump(graph, f)\n","\n","        # Save the final result in SGG format\n","        save_sg_format(img_path, nodes4, edges4)\n","    print('\\n')"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"hyyCOzd2Ot4j"},"source":["## Generating Groundtruth"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"tags":[],"id":"w1dOrUDxOt4j"},"outputs":[],"source":["for filename in os.listdir(f'{dir_eval_io}0_images'):\n","    img_path = f'{dir_eval_io}/0_images/{filename}'\n","    img_id = int(img_path.split('0_images/')[1].split('.jpg')[0])\n","    box_labels = list()\n","    rel_labels = list()\n","    if os.path.exists(f'{dir_eval_io}0_gt_scene_graphs/'+img_path.split('0_images/')[1]+'_gt_gqa'):\n","        #print('***** EXISTS: '+ img_path +' *****')\n","        continue\n","    else:\n","        #print('***** PROCESSING '+ img_path +' *****')\n","        for img in gqa_rels_json:\n","            if img['image_id'] == img_id:\n","                for rel in img['relationships']:\n","                    if rel['predicate'].lower() in gqa_unique_rels:\n","                        # in relationships.json, there is either 'name' or 'names' key for subject and object\n","                        pred = rel['predicate'].lower()\n","                        if 'name' in rel['subject'].keys():\n","                            if 'name' in rel['object'].keys():\n","                                subj = rel['subject']['name']\n","                                obj = rel['object']['name']\n","                            else:\n","                                subj = rel['subject']['name']\n","                                obj = rel['object']['names'][0]\n","                        else:\n","                            if 'name' in rel['object'].keys():\n","                                subj = rel['subject']['names'][0]\n","                                obj = rel['object']['name']\n","                            else:\n","                                subj = rel['subject']['names'][0]\n","                                obj = rel['object']['names'][0]\n","                        if (subj in gqa_unique_objs) and (obj in gqa_unique_objs):\n","                            if subj in box_labels:\n","                                subj_id = box_labels.index(subj)\n","                            else:\n","                                box_labels.append(subj)\n","                                subj_id = box_labels.index(subj)\n","                            if obj in box_labels:\n","                                obj_id = box_labels.index(obj)\n","                            else:\n","                                box_labels.append(obj)\n","                                obj_id = box_labels.index(obj)\n","                            rel_labels.append(str(subj_id)+'_'+subj +' => '+ pred +' => '+ str(obj_id)+'_'+obj)\n","        g = draw_graph(box_labels,rel_labels)\n","        g.render(f'{dir_eval_io}0_gt_scene_graphs/'+img_path.split('0_images/')[1]+'_gt_gqa')"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"gP5HXlWTOt4j"},"source":["## Evaluation on GQA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KzXJzlgqOt4j"},"outputs":[],"source":["import json, os, numpy as np, copy\n","os.chdir('/home/jaleed/Jaleed')\n","gqa_rels_json = json.load(open('CSKG/relationships.json'))\n","gqa_dict = json.load(open('CSKG/GQA-SGG-dicts-with-attri.json'))\n","gqa_unique_objs = list(dict.fromkeys(gqa_dict['object_count'].keys()))\n","gqa_unique_rels = list(dict.fromkeys(gqa_dict['predicate_count'].keys()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37OsQE4UOt4k","outputId":"f95b1af3-d262-44b2-f3eb-dd9e415ba14a"},"outputs":[{"name":"stdout","output_type":"stream","text":["50 done\n","100 done\n","gqa done\n"]}],"source":["results = {}\n","\n","for dataset in ['gqa']:\n","\n","    overall_recall = list()\n","    overall_recall_cs = list()\n","    overall_m_recall = list()\n","    overall_m_recall_cs = list()\n","\n","    for K in [50,100]:\n","\n","        pred_sg_dir = f'Eval_IO/{dataset}/1_pred_scene_graphs/'\n","        pred_sg_dir_cs = f'Eval_IO/{dataset}/2_enriched_scene_graphs/'\n","        assert(os.listdir(pred_sg_dir) == os.listdir(pred_sg_dir_cs))\n","\n","        recall = list() #R@K for scene graphs\n","        recall_cs = list() #R@K for enriched scene graphs\n","        m_recall = list() #mR@K for scene graphs\n","        m_recall_cs = list() #mR@K for enriched scene graphs\n","\n","        l = os.listdir(pred_sg_dir)\n","        #l[-2:] = []\n","        #l=l[0:5]\n","        for pred_sg in l: #['2317213.jpg']\n","            # 1/3 Retrieve groundtruth predicates\n","            gt_rels = [img['relationships'] for img in gqa_rels_json if img['image_id']==int(pred_sg.split('.')[0])][0]\n","            gt_predicates = list()\n","            for gt_rel in gt_rels:\n","                if 'name' in gt_rel['subject'].keys():\n","                    obj1 = gt_rel['subject']['name']\n","                else:\n","                    obj1 = gt_rel['subject']['names'][0]\n","                if 'name' in gt_rel['object'].keys():\n","                    obj2 = gt_rel['object']['name']\n","                else:\n","                    obj2 = gt_rel['object']['names'][0]\n","                rel = gt_rel['predicate'].lower()\n","\n","                if rel in gqa_unique_rels:\n","                    gt_predicates.append(rel)\n","\n","            # Retrieve keys (idnices of obj/pred labels)\n","            custom_data_info = json.load(open(pred_sg_dir+pred_sg+'/custom_data_info.json'))\n","            ind_to_classes = custom_data_info['ind_to_classes']\n","            ind_to_predicates = custom_data_info['ind_to_predicates']\n","\n","            # 2/3 Retrieve predicted predicates (without commonsense)\n","            custom_prediction = json.load(open(pred_sg_dir+pred_sg+'/custom_prediction.json'))\n","            bbox_labels = custom_prediction['0']['bbox_labels']\n","            bbox_scores = custom_prediction['0']['bbox_scores']\n","            rel_pairs = custom_prediction['0']['rel_pairs']\n","            rel_labels = custom_prediction['0']['rel_labels']\n","            rel_scores = custom_prediction['0']['rel_scores']\n","            pred_objects = [ind_to_classes[ind] for ind in bbox_labels]\n","            pred_object_pairs = [[pred_objects[inds[0]],pred_objects[inds[1]]] for inds in rel_pairs]\n","            pred_predicates = [ind_to_predicates[ind] for ind in rel_labels]\n","            assert(len(pred_object_pairs)==len(pred_predicates))\n","            k_pred_predicates = pred_predicates[:min(K,len(pred_predicates))] # Top K Predicted Predicates\n","\n","            # Compute Recall@K\n","            count_preds = 0 # number of correct predicted predicates\n","            gt_predicates1=copy.deepcopy(gt_predicates)\n","            for i in range(0,len(k_pred_predicates)):\n","                if k_pred_predicates[i] in gt_predicates1:\n","                    count_preds += 1\n","                    gt_predicates1.pop(gt_predicates1.index(k_pred_predicates[i]))\n","\n","            if len(gt_predicates)>0:\n","                recall.append(count_preds*100/len(gt_predicates))\n","            else:\n","                #pass\n","                recall.append(0)\n","\n","            # Computer mR@K\n","            gqa_unique_rels_recall = list()\n","            for i in range(0,50):\n","                k_pred_predicates1 = [p for p in k_pred_predicates if p==gqa_unique_rels[i]] # subset of k_pred_predicates containing only i-th unique_rel\n","                gt_predicates1 = [p for p in gt_predicates if p==gqa_unique_rels[i]] # subset of gt_predicates containing only i-th unique_rel\n","                if len(gt_predicates1)==0 or len(k_pred_predicates1)==0:\n","                    gqa_unique_rels_recall.append(0)\n","                else:\n","                    gqa_unique_rels_recall.append(len(k_pred_predicates1)*100/max(len(gt_predicates1),len(k_pred_predicates1)))\n","            m_recall.append(np.mean(gqa_unique_rels_recall))\n","\n","\n","            # 3/3 Retrieve predicted predicates (with commonsense)\n","            custom_prediction = json.load(open(pred_sg_dir_cs+pred_sg+'/custom_prediction.json'))\n","            bbox_labels = custom_prediction['0']['bbox_labels']\n","            rel_pairs = custom_prediction['0']['rel_pairs']\n","            rel_labels = custom_prediction['0']['rel_labels']\n","            rel_scores = custom_prediction['0']['rel_scores']\n","            pred_objects = [ind_to_classes[ind] for ind in bbox_labels]\n","            pred_object_pairs = [[pred_objects[inds[0]],pred_objects[inds[1]]] for inds in rel_pairs]\n","            pred_predicates = [ind_to_predicates[ind] for ind in rel_labels]\n","            assert(len(pred_object_pairs)==len(pred_predicates))\n","            k_pred_predicates = pred_predicates[:min(K,len(pred_predicates))] # Top K Predicted Predicates\n","\n","            # Compute Recall@K\n","            count_preds = 0 # number of correct predicted predicates\n","            gt_predicates2=copy.deepcopy(gt_predicates)\n","            for i in range(0,len(k_pred_predicates)):\n","                if k_pred_predicates[i] in gt_predicates2:\n","                    count_preds += 1\n","                    gt_predicates2.pop(gt_predicates2.index(k_pred_predicates[i]))\n","\n","            if len(gt_predicates)>0:\n","                recall_cs.append(count_preds*100/len(gt_predicates))\n","            else:\n","                #pass\n","                recall_cs.append(0)\n","\n","            # Computer mR@K\n","            gqa_unique_rels_recall = list()\n","            for i in range(0,50):\n","                k_pred_predicates1 = [p for p in k_pred_predicates if p==gqa_unique_rels[i]] # subset of k_pred_predicates containing only i-th unique_rel\n","                gt_predicates1 = [p for p in gt_predicates if p==gqa_unique_rels[i]] # subset of gt_predicates containing only i-th unique_rel\n","                if len(gt_predicates1)==0 or len(k_pred_predicates1)==0:\n","                    gqa_unique_rels_recall.append(0)\n","                else:\n","                    gqa_unique_rels_recall.append(len(k_pred_predicates1)*100/max(len(gt_predicates1),len(k_pred_predicates1)))\n","            m_recall_cs.append(np.mean(gqa_unique_rels_recall))\n","\n","        print(K, 'done')\n","\n","        overall_recall.append(sum(recall)/len([r for r in recall]))\n","        overall_recall_cs.append(sum(recall_cs)/len([r for r in recall_cs]))\n","        overall_m_recall.append(sum(m_recall)/len([r for r in m_recall]))\n","        overall_m_recall_cs.append(sum(m_recall_cs)/len([r for r in m_recall_cs]))\n","\n","    print(dataset, 'done')\n","    results[dataset] = [overall_recall, overall_recall_cs, overall_m_recall, overall_m_recall_cs]\n","json.dump(results, open(f'Eval_IO/{dataset}/results.json','w'))"]},{"cell_type":"code","source":["results = json.load(open(f'Eval_IO/{dataset}/results1.json'))\n","print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cWlGeCsO77-","executionInfo":{"status":"ok","timestamp":1728661484722,"user_tz":-60,"elapsed":399,"user":{"displayName":"Jaleed Khan","userId":"02490424589062944841"}},"outputId":"91a5e1ba-da1c-4d81-88a7-5d5738bb590d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["{'gqa': [[29.2172208937719, 32.69647206780441], [36.031804134886141, 41.721526939683707], [10.190612309145152, 12.11504329083056], [12.380390450797544, 15.104173263905842]]}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2dWQjzROt4m"},"outputs":[],"source":[]}],"metadata":{"instance_type":"ml.t3.xlarge","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}